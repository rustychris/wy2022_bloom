{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "2f2ba1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to combine the DFM aspects of dfm_rs_and_chl_runs\n",
    "# and the age/nitrate/etc. aspects of run_tracers_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "9c99424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/richmondvol1/rusty/stompy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5e3b33b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import datetime\n",
    "import six\n",
    "import xarray as xr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a678e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stompy.spatial import field\n",
    "from stompy import utils\n",
    "from shapely import geometry\n",
    "\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "import stompy.model.delft.dflow_model as dfm\n",
    "import stompy.model.delft.waq_scenario as dwaq\n",
    "from stompy.grid import unstructured_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import logging as log\n",
    "from scipy.interpolate import griddata\n",
    "from stompy.spatial import proj_utils\n",
    "import numpy as np\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "8483750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bloom_common\n",
    "scene_df = bloom_common.load_chl_scenes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "642edfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloom_common import load_scene, load_scene_utm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "69b73c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "six.moves.reload_module(dwaq)\n",
    "\n",
    "# with dfm_spinup in place, no need to go back to this original run.\n",
    "\n",
    "#if 1: # longer, 16 layer run.\n",
    "#    # The DFM setup that we're repurposing\n",
    "#    dfm_path=\"/chicagovol1/hpcshared/open_bay/hydro/full_res/wy2022_bloom/runs/wy2022_bloom_16layer\"    \n",
    "#    #dwaq_hydro=os.path.join(dfm_path, \"DFM_DELWAQ_wy2022_bloom_16layer\")\n",
    "#    #hydro=dwaq.HydroFiles(os.path.join(dwaq_hydro,\"wy2022_bloom_16layer.hyd\"))\n",
    "\n",
    "bloom_common.configure_dfm_t140737() # broken for dwaq, but hopefully works for dfm-online-dwaq\n",
    "#bloom_common.configure_dfm_2023_01() # used to be configure_dwaq_new()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f163ecbe",
   "metadata": {},
   "source": [
    "DFM-based Runs\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b5bcb928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart files every 10 days, plus a restart file on 2022-08-01.\n",
    "# speed was 85x realtime on 16 cores.\n",
    "# Forcing should all be okay to copy/link for restarts.\n",
    "\n",
    "if 1: # Check on map and rst output:\n",
    "    dfm_base_run_dir=\"dfm_spinup\"\n",
    "    map_fn=os.path.join(dfm_base_run_dir,\n",
    "                        \"DFM_OUTPUT_wy2022_bloom_16layer\",\n",
    "                        \"wy2022_bloom_16layer_0000_20220501_000000_map.nc\")\n",
    "    rst_fn=os.path.join(dfm_base_run_dir,\n",
    "                        \"DFM_OUTPUT_wy2022_bloom_16layer\",\n",
    "                        \"wy2022_bloom_16layer_0000_20220801_000000_rst.nc\")\n",
    "    \n",
    "#map_ds=xr.open_dataset(map_fn)\n",
    "#rst_ds=xr.open_dataset(rst_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "1db7d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "six.moves.reload_module(dfm)\n",
    "six.moves.reload_module(bloom_common)\n",
    "import pdb\n",
    "\n",
    "# First, get a basic restart going\n",
    "class SFBRestartable(dfm.DFlowModel):\n",
    "    \"\"\"\n",
    "    Add special sauce to symlink relevant forcing files that are\n",
    "    not standard for dflow_model.\n",
    "    This includes bc_files, src_files, meteo_coarse.grd\n",
    "    \"\"\"\n",
    "    restart_copy_names=[\"source_files\"] # symlink everything\n",
    "\n",
    "    def copy_files_for_restart(self):\n",
    "        super().copy_files_for_restart()\n",
    "        prev_model=self.restart_from\n",
    "        # Subdirectories are not automatically copied over, as well as meteo_coarse.grd\n",
    "        for sub in ['bc_files','source_files','meteo_coarse.grd']:\n",
    "            src=os.path.join(prev_model.run_dir,sub)\n",
    "            if not os.path.exists(src):\n",
    "                self.log.warning(f\"Expected to symlink {src} but it wasn't there.\")\n",
    "                continue\n",
    "            dst=os.path.join(self.run_dir,sub)\n",
    "            if os.path.exists(dst):\n",
    "                self.log.warning(f\"Expected to make {dst} a copy or symlink but it already exists\")\n",
    "                continue\n",
    "\n",
    "            if sub in self.restart_copy_names:\n",
    "                self.log.info(f\"Copy {src} => {dst}\")\n",
    "                shutil.copytree(src,dst)\n",
    "            else:\n",
    "                # TODO: chase down symlinks to get back to the real file\n",
    "                # otherwise this will break if intermediate runs are removed.\n",
    "                # Make the symlinks relative in all of this moves, is on a different machine, etc.\n",
    "                src_rel=os.path.relpath(src,start=self.run_dir)\n",
    "                self.log.info(f\"Symlink {dst} => {src_rel}\")\n",
    "                os.symlink(src_rel,dst)        \n",
    "\n",
    "prev_model=SFBRestartable.load(dfm_base_run_dir)\n",
    "\n",
    "\n",
    "# And the remote sensed imagery part \n",
    "class AgeDfm:\n",
    "    name=\"data_agedfm_v00\"\n",
    "    run_dir_prefix=\"run\" # {name}/{run_dir_prefix}_{dates}_{version}\n",
    "\n",
    "    # Will start from the end of this existing run (which doesn't have the tracers)\n",
    "    dfm_base_run_dir=\"dfm_spinup\"\n",
    "    # run_dir that gets us up to run_start\n",
    "    pre_run_dir=None\n",
    "    \n",
    "    # spinup will be run without tracers up to this date:\n",
    "    run_start=np.datetime64(\"2022-08-08\")\n",
    "    run_stop =np.datetime64(\"2022-08-30\")\n",
    "    \n",
    "    #tracers_per_speed=['weight','wvalue','uniform']\n",
    "    swim_speeds=[0.0] # positive down, m/s\n",
    "    \n",
    "    restart_copy_names=[\"source_files\"] # copy, because we end up modifying some\n",
    "    \n",
    "    initial_condition='mixed' # only support mixed right now\n",
    "    \n",
    "    polygons={'oakland':bloom_common.oakland_poly,\n",
    "              'eastshore':bloom_common.eastshore_poly}\n",
    "\n",
    "    # HERE - copy in the tracer setup.\n",
    "    # Maybe move custom tracer code to bloom_common.\n",
    "    \n",
    "    def run_simulations(self):\n",
    "        \"\"\"\n",
    "        Find a restart point close to start_scene_idx, \n",
    "        initialize, run to stop_scene_idx. If start_scene_idx is\n",
    "        negative, skip tracer setup, just trying to get a restart file\n",
    "        that matches stop_scene_idx, and assuming that the last \n",
    "        \"\"\"\n",
    "        self.run_to_start()\n",
    "        # self.run_start_to_stop()\n",
    "        \n",
    "    def run_to_start(self):\n",
    "        prev_model=SFBRestartable.load(self.dfm_base_run_dir)            \n",
    "        restart_time=prev_model.restartable_time()\n",
    "        \n",
    "        assert restart_time < self.run_start\n",
    "        \n",
    "        # Setup a restart and then check whether it already exists\n",
    "        # before actually running it.\n",
    "        model=prev_model.create_restart(deep=True)\n",
    "        model.run_stop=self.run_start # we're just trying to get up to the start\n",
    "        self.set_run_dir(model)\n",
    "        \n",
    "        self.pre_run_dir=model.run_dir\n",
    "        \n",
    "        if dfm.DFlowModel.run_completed(model.run_dir):\n",
    "            print(\"Run to start time is already complete\")\n",
    "            return\n",
    "\n",
    "        # no tracers for this part\n",
    "        # though if we start adding swimming and want a good IC,\n",
    "        # here is where a uniform+swimming tracer could be added.\n",
    "        # self.set_scene_tracers(model,start_scene_idx)\n",
    "            \n",
    "        self.generally_configure(model)\n",
    "        # This alters the MDU, so do it before write()\n",
    "        # self.update_restart_with_tracers(model)\n",
    "        model.write()\n",
    "        # This updates the BC data in place. Do it here so that \n",
    "        # we have a starting ext file which will be updated with\n",
    "        # new tracers.\n",
    "        # self.add_tracers_to_bcs(model,self.tracers)\n",
    "        model.partition()\n",
    "        model.run_simulation()\n",
    "\n",
    "    def run_start_to_stop(self):\n",
    "        prev_model=SFBRestartable.load(self.pre_run_dir)            \n",
    "\n",
    "        # Setup a restart\n",
    "        model=prev_model.create_restart(deep=True)\n",
    "        model.run_stop=self.run_stop\n",
    "        \n",
    "        self.set_run_dir(model)\n",
    "\n",
    "        self.set_scene_tracers(model)\n",
    "            \n",
    "        self.generally_configure(model)\n",
    "        # This alters the MDU, so do it before write()\n",
    "        self.update_restart_with_tracers(model)\n",
    "        model.write()\n",
    "        # This updates the BC data in place. Do it here so that \n",
    "        # we have a starting ext file which will be updated with\n",
    "        # new tracers.\n",
    "        self.add_tracers_to_bcs(model,self.tracers)\n",
    "        model.partition()\n",
    "        model.run_simulation()\n",
    "\n",
    "    def generally_configure(self,model):\n",
    "        model.mdu['output','WaqInterval']=\"\" # no need for DWAQ output\n",
    "\n",
    "        bloom_common.configure_dfm_t140737()\n",
    "        model.dfm_bin_dir=os.path.join(os.environ['DELFT_SRC'],'bin')\n",
    "        model.mpi_bin_dir=os.path.join(os.environ['DELFT_SRC'],'bin')\n",
    "        \n",
    "        bloom_common.set_minimal_map_output(model)\n",
    "        \n",
    "        model.mdu['output','MapInterval']=\"900\" # make some nice animations\n",
    "\n",
    "    \n",
    "    def set_run_dir(self,model):\n",
    "        start_str,stop_str=[ utils.to_datetime(t).strftime(\"%Y%m%dT%H%M\")\n",
    "                            for t in [model.run_start,model.run_stop]]\n",
    "        for x in range(20):\n",
    "            run_dir=os.path.join(self.name,f\"{self.run_dir_prefix}_{start_str}_{stop_str}_v{x:02}\")\n",
    "            if not os.path.exists(run_dir): break\n",
    "        else:\n",
    "            raise Exception(f\"Too many retries for {run_dir}\")\n",
    "        model.run_dir=run_dir\n",
    "        model.set_restart_file() # kludge. RestartFile needs run_dir.\n",
    "    \n",
    "    def set_scene_tracers(self,model,start_scene_idx):\n",
    "        # Replace the RS-based code with simple polygon blob\n",
    "        # Allow multiple swimming speeds but don't bother with stratified IC.\n",
    "        assert self.initial_condition=='mixed'\n",
    "        tracers=[]\n",
    "    \n",
    "        for swim_i,swim_speed in enumerate(self.swim_speeds): # positive down.\n",
    "            for tracer_type in self.tracers_per_speed:\n",
    "                # HERE - adapt with the age tracers\n",
    "                assert tracer_type in self.polygons\n",
    "                tracer_name=tracer_type+str(swim_i)\n",
    "                \n",
    "                def tracer_func(rst_ds,values_cell_layer,tracer_type=tracer_type,\n",
    "                                incoming_uniform=None,swim_i=swim_i):\n",
    "                    if swim_speed!=0.0 and self.initial_condition=='stratified':\n",
    "                        vert_scale = incoming_uniform[swim_i]\n",
    "                    else:\n",
    "                        vert_scale=1.0\n",
    "                    # vert_scale is guaranteed to have unit concentration in the surface\n",
    "                    # layer of all cells.\n",
    "\n",
    "                    polygon=self.polygons[tracer_type]                    \n",
    "                    xy=np.c_[ rst_ds.FlowElem_xzw.values, rst_ds.FlowElem_yzw.values]\n",
    "\n",
    "                    cells=[polygon.contains(geometry.Point(x,y)) \n",
    "                           for x,y in zip(rst_ds.FlowElem_xzw.values, rst_ds.FlowElem_yzw.values)]\n",
    "                    value_2d=100*np.array(cells,np.float64)\n",
    "                    values_cell_layer[:,:] = value_2d[:,None]\n",
    "\n",
    "                tracers.append( dict(name=tracer_name,func=tracer_func,\n",
    "                                     fall_velocity_m_s=swim_speed))            \n",
    "            \n",
    "        self.tracers=tracers\n",
    "\n",
    "    def update_restart_with_tracers(self,model):\n",
    "        def modify_ic(rst_ds,**kw):\n",
    "            assert self.initial_condition=='mixed'\n",
    "            incoming_uniform=None\n",
    "            \n",
    "            for tracer in self.tracers:\n",
    "                name=tracer['name']\n",
    "                func=tracer['func']\n",
    "                model.log.info(f\"Setting tracer {name} in restart file\")\n",
    "                # mimic sa1 tracer\n",
    "                salt=rst_ds['sa1']\n",
    "                values=salt.values.copy() # ('time','nFlowElem','laydim')\n",
    "                values[...] = 0.0 # don't accidentally write salt data though\n",
    "                \n",
    "                # updates values in place.\n",
    "                func(rst_ds=rst_ds,values_cell_layer=values[0,:,:], \n",
    "                     incoming_uniform=incoming_uniform)\n",
    "                rst_ds[name]=salt.dims, values\n",
    "                for aname in ['coordinates','grid_mapping']:\n",
    "                    if aname in salt.attrs:\n",
    "                        rst_ds[name].attrs[aname]=salt.attrs[aname]\n",
    "        model.modify_restart_data(modify_ic)                \n",
    "\n",
    "    def add_tracers_to_bcs(self,model,tracers):\n",
    "        # take a more low-level approach compared to usual BC configuration\n",
    "        # so that we can be very careful about what things change.\n",
    "        ext_fn=model.mdu.filepath(('external forcing','ExtForceFile'))\n",
    "        orig_ext_fn=ext_fn+\".orig\"\n",
    "        # This check is more for dev -- it is fragile in the sense that if\n",
    "        # orig_ext_fn *should* be different, we'll end up still using the\n",
    "        # old file.\n",
    "        if not os.path.exists(orig_ext_fn):\n",
    "            shutil.copyfile(ext_fn,orig_ext_fn)\n",
    "\n",
    "        bcs=model.parse_old_bc(orig_ext_fn)\n",
    "        \n",
    "        new_tracer_names=[t['name'] for t in tracers]\n",
    "        configured_tracers={}\n",
    "        \n",
    "        # For now all boundary conditions for all new tracers are 0.\n",
    "        # Note that establishing order here is very confusing. If these\n",
    "        # need to be nonzero, it will take some work to know that \n",
    "        # it's correct. probably the strategy should be to filter out \n",
    "        # all existing BCs for these tracers, and then write them at the\n",
    "        # end in our prescribed order. Yeah, that's what I'm doing.\n",
    "        new_bc_values=[0.0 for t in tracers]\n",
    "\n",
    "        def name_matches(cfg_name):\n",
    "            for tracer in tracers:\n",
    "                if tracer['name'].lower() == cfg_name.lower():\n",
    "                    if tracer['name']!=cfg_name:\n",
    "                        print(f\"Careful - case mismatch {cfg_name} vs {tracer['name']}\")\n",
    "                    return True\n",
    "            return False\n",
    "            \n",
    "        with open(ext_fn,'wt') as fp_new:\n",
    "            for rec in bcs:\n",
    "                write_verbatim=True\n",
    "                \n",
    "                quantity=rec['QUANTITY']\n",
    "                if quantity.upper().startswith('INITIALTRACER'):\n",
    "                    tracer_name=quantity[len(\"INITIALTRACER\"):]\n",
    "                    #if name_matches(tracer_name): continue\n",
    "                    # Assume that we will rewrite *all* tracers.\n",
    "                    # otherwise we have to keep track of how many tracers\n",
    "                    # are along for the ride in addition to the ones we're\n",
    "                    # adding.\n",
    "                    continue\n",
    "                    # Tracer ICs we care about just because they help establish the\n",
    "                    # list of tracers, but no need to change these entries.\n",
    "                    # Actually, will just write out fresh stanzas for these in order\n",
    "                    # to force the ordering.\n",
    "                    # configured_tracers[tracer_name]=True\n",
    "                elif quantity.upper().startswith('TRACERBND'):\n",
    "                    tracer_name=quantity[len(\"TRACERBND\"):]\n",
    "                    #if name_matches(tracer_name): continue\n",
    "                    continue # as above.\n",
    "                    # And for now we leave boundary conditions as is, but again\n",
    "                    # remember that this tracer has been configured.\n",
    "                    #configured_tracers[tracer_name]=True\n",
    "                elif quantity.upper().startswith('DISCHARGE_SALINITY_TEMPERATURE_SORSIN'):\n",
    "                    print(\"Source/sink BC entry\")\n",
    "                    # Yuck - have to add new column(s). This only involves rewriting \n",
    "                    # the data file,though. The stanza is unchanged.\n",
    "                    self.add_tracer_bcs(model,rec,new_values=new_bc_values,orig_num_values=3)\n",
    "\n",
    "                # At this point nobody every changes the stanza, it's all written verbatim.\n",
    "                if write_verbatim:\n",
    "                    fp_new.write(\"\\n\".join(rec['stanza'])+\"\\n\")\n",
    "                    continue\n",
    "                \n",
    "            # And write out our new tracers (including ones that were skipped during \n",
    "            # transcription above\n",
    "            for tracer in self.tracers:\n",
    "                name=tracer['name']\n",
    "                ic_fn=f\"dummy-{name}.xyz\"\n",
    "                with open(os.path.join(model.run_dir,ic_fn),'wt') as fp_xyz:\n",
    "                    fp_xyz.write(\"550000 4180000 0.0\\n\")\n",
    "                fp_new.write(\"\\n# NEW TRACERS\\n\"\n",
    "                             f\"QUANTITY=initialtracer{name}\\n\"\n",
    "                             f\"FILENAME={ic_fn}\\n\"\n",
    "                             \"FILETYPE=7\\n\"\n",
    "                             \"METHOD=5\\n\"\n",
    "                             \"OPERAND=O\\n\")\n",
    "                if tracer['fall_velocity_m_s']!=0.0:\n",
    "                    w=tracer['fall_velocity_m_s']\n",
    "                    fp_new.write(f\"TRACERFALLVELOCITY={w:.8f}\\n\")\n",
    "\n",
    "    def add_tracer_bcs(self,model,bc,new_values=[],orig_num_values=3):\n",
    "        \"\"\"\n",
    "        Add additional columns to a source/sink data file.\n",
    "        So if the new run will include two dwaq tracers, pass new_values=[0,1]\n",
    "        (which would tag sources with 0 for the first and 1.0 for the second)\n",
    "        orig_num_values: 3 for run with salinity and temperature. I think\n",
    "        less than that if temperature and/or salinity are disabled. \n",
    "        \"\"\"\n",
    "        # yuck...\n",
    "        pli_fn=os.path.join(model.run_dir,bc['FILENAME'])\n",
    "        assert pli_fn.lower().endswith('.pli')\n",
    "        fn=pli_fn[:-4] + \".tim\"\n",
    "        assert os.path.exists(fn)\n",
    "        fn_orig=fn+\".orig\"\n",
    "        if not os.path.exists(fn_orig):\n",
    "            shutil.copyfile(fn,fn_orig)\n",
    "        data_orig=np.loadtxt(fn_orig)\n",
    "        # drop previous forcing for new tracers. leaving time column and the original Q,S,T values\n",
    "        columns=[data_orig[:,:1+orig_num_values]] \n",
    "        for new_val in new_values:\n",
    "            columns.append( np.full(data_orig.shape[0],new_val))\n",
    "        data=np.column_stack(columns)\n",
    "        np.savetxt(fn,data,fmt=\"%.6g\")\n",
    "        \n",
    "        \n",
    "# Bringing in the age-tracer setup\n",
    "# Exactly what tracers do I even care about?\n",
    "# Most basic - could use the existing blob runs along with exponential growth.\n",
    "# Next would be to cap at some concentration related to nutrient limitation.\n",
    "# there were runs that also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "d689e932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HydroModel:set_restart_file: Setting RestartFile based on self.restart_from\n",
      "INFO:HydroModel:set_restart_file: Setting RestartFile based on self.restart_from\n",
      "INFO:HydroModel:Could not find BC to get initial water level\n",
      "WARNING:HydroModel:SKIPPING self.set_restart_file()\n",
      "INFO:DFlowModel:Writing MDU to data_agedfm_v00/run_20220801T0000_20220808T0000_v00/wy2022_bloom_16layer.mdu\n",
      "INFO:HydroModel:Symlink data_agedfm_v00/run_20220801T0000_20220808T0000_v00/bc_files => ../../dfm_spinup/bc_files\n",
      "INFO:HydroModel:Copy dfm_spinup/source_files => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/source_files\n",
      "INFO:HydroModel:Symlink data_agedfm_v00/run_20220801T0000_20220808T0000_v00/meteo_coarse.grd => ../../dfm_spinup/meteo_coarse.grd\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0000_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0000_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0001_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0001_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0002_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0002_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0003_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0003_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0004_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0004_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0005_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0005_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0006_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0006_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0007_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0007_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0008_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0008_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0009_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0009_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0010_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0010_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0011_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0011_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0012_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0012_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0013_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0013_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0014_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0014_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0015_net.nc => data_agedfm_v00/run_20220801T0000_20220808T0000_v00/sfei_v20_0015_net.nc\n",
      "/bin/bash: /home/rusty/.conda/envs/dfm_t140737/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "INFO:HydroModel:Running command: /opt/software/delft/dfm/t140737/bin/mpiexec -n 16 /opt/software/delft/dfm/t140737/bin/dflowfm -t 1 --autostartstop wy2022_bloom_16layer.mdu\n",
      "application called MPI_Abort(MPI_COMM_WORLD, 1) - process 14\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['/opt/software/delft/dfm/t140737/bin/mpiexec', '-n', '16', '/opt/software/delft/dfm/t140737/bin/dflowfm', '-t', '1', '--autostartstop', 'wy2022_bloom_16layer.mdu']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [285]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m agedfm\u001b[38;5;241m=\u001b[39mAgeDfm() \n\u001b[0;32m----> 2\u001b[0m \u001b[43magedfm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_simulations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [284]\u001b[0m, in \u001b[0;36mAgeDfm.run_simulations\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_simulations\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Find a restart point close to start_scene_idx, \u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    initialize, run to stop_scene_idx. If start_scene_idx is\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    negative, skip tracer setup, just trying to get a restart file\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    that matches stop_scene_idx, and assuming that the last \u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_to_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [284]\u001b[0m, in \u001b[0;36mAgeDfm.run_to_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# This updates the BC data in place. Do it here so that \u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# we have a starting ext file which will be updated with\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# new tracers.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# self.add_tracers_to_bcs(model,self.tracers)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m model\u001b[38;5;241m.\u001b[39mpartition()\n\u001b[0;32m--> 111\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/richmondvol1/rusty/stompy/stompy/model/delft/dflow_model.py:656\u001b[0m, in \u001b[0;36mDFlowModel.run_simulation\u001b[0;34m(self, threads, extra_args)\u001b[0m\n\u001b[1;32m    653\u001b[0m     cmd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdwaq\u001b[38;5;241m.\u001b[39mupdate_command(cmd)\n\u001b[1;32m    655\u001b[0m cmd \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m extra_args\n\u001b[0;32m--> 656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_dflowfm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/richmondvol1/rusty/stompy/stompy/model/delft/dflow_model.py:632\u001b[0m, in \u001b[0;36mDFlowModel.run_dflowfm\u001b[0;34m(self, cmd, mpi, wait)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_procs\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    631\u001b[0m     real_cmd\u001b[38;5;241m=\u001b[39m( [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdflowfm_exe] \u001b[38;5;241m+\u001b[39m cmd )\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmpirun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_cmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mworking_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     real_cmd\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdflowfm_exe]\u001b[38;5;241m+\u001b[39mcmd\n",
      "File \u001b[0;32m/richmondvol1/rusty/stompy/stompy/model/hydro_model.py:1051\u001b[0m, in \u001b[0;36mMpiModel.mpirun\u001b[0;34m(self, cmd, num_procs, working_dir, wait)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# TODO: mpi_flavor is currently handling multiple roles: how to start\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# a job, and to some degree the machinery that is running behind the scenes.\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmpi_flavor\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmpiexec\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmpirun_mpiexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_procs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mworking_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmpi_flavor\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslurm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmpirun_slurm(cmd,num_procs,working_dir,wait\u001b[38;5;241m=\u001b[39mwait)\n",
      "File \u001b[0;32m/richmondvol1/rusty/stompy/stompy/model/hydro_model.py:1067\u001b[0m, in \u001b[0;36mMpiModel.mpirun_mpiexec\u001b[0;34m(self, cmd, num_procs, working_dir, wait)\u001b[0m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m( (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest to start MPI process \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1065\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(flavor=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) without waiting not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m%\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmpi_flavor)\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning command: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(real_cmd)))\n\u001b[0;32m-> 1067\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_with_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_cmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mworking_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/richmondvol1/rusty/stompy/stompy/utils.py:2359\u001b[0m, in \u001b[0;36mcall_with_path\u001b[0;34m(cmd, path)\u001b[0m\n\u001b[1;32m   2357\u001b[0m     shell\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mtype\u001b[39m(cmd) \u001b[38;5;129;01min\u001b[39;00m six\u001b[38;5;241m.\u001b[39mstring_types)\n\u001b[1;32m   2358\u001b[0m     \u001b[38;5;66;03m# return subprocess.call(cmd,shell=shell)\u001b[39;00m\n\u001b[0;32m-> 2359\u001b[0m     output\u001b[38;5;241m=\u001b[39m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m   2361\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/general_rh/lib/python3.9/subprocess.py:424\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    422\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[0;32m--> 424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/.conda/envs/general_rh/lib/python3.9/subprocess.py:528\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    529\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['/opt/software/delft/dfm/t140737/bin/mpiexec', '-n', '16', '/opt/software/delft/dfm/t140737/bin/dflowfm', '-t', '1', '--autostartstop', 'wy2022_bloom_16layer.mdu']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "agedfm=AgeDfm() \n",
    "agedfm.run_simulations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d26797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
