{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fccc6438",
   "metadata": {},
   "source": [
    "Transport and Swimming Tracers\n",
    "--\n",
    "\n",
    "**v01: move to DFM without temperature.**\n",
    "\n",
    "Don't actually have a non-temperature, wy2022 run with DWAQ output. So the machinery here\n",
    "mostly copies run_dfm_bloom_tracers_v01.\n",
    "\n",
    "Feed in Kd and insolation data.\n",
    "\n",
    "After the run, compile maps of instantaneous growth potential, based on \n",
    "normalized vertical distribution integrated with light limitation function.\n",
    "\n",
    "Complicating factors:\n",
    " - For buoyant tracers, depth-uniform initialization in the coastal ocean\n",
    "   leads to high surface concentrations, which could then mix into the Bay.\n",
    "   Practically, should be safe to assume that the time for that elevated\n",
    "   concentration to be transported into the Bay is long relative to the time \n",
    "   for the vertical profile to come into balance.\n",
    "\n",
    "A secondary run could/will create a series of releases at times of RS\n",
    "scenes, and integrate until the next scene. Vertical distribution of release\n",
    "is the tricky part. All at the surface? Following the distribution from the \n",
    "previous run, normalized to get match surface concentration to RS? Depth-uniform?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0360f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/richmondvol1/rusty/stompy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e49a3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, shutil\n",
    "import datetime\n",
    "import six\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from stompy.spatial import field\n",
    "from stompy import utils\n",
    "from stompy.plot import plot_wkb\n",
    "import xarray as xr\n",
    "from scipy import ndimage\n",
    "\n",
    "import stompy.model.delft.dflow_model as dfm\n",
    "import stompy.model.delft.waq_scenario as dwaq\n",
    "from stompy.grid import unstructured_grid\n",
    "from shapely import geometry\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2751e34e-f0fb-42f0-be82-f8576c692d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bloom_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32586625-019f-4f04-9e67-c7c0e499f315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525600"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "365*24*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d65aae0-2099-476a-bf82-0cfa6dacf874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get a basic restart going\n",
    "from stompy.model.delft import custom_process\n",
    "\n",
    "class Model(custom_process.CustomProcesses,bloom_common.SFBRestartable):\n",
    "    dwaq=False # will have to bring in Kd, rad after the fact.\n",
    "    temperature=False\n",
    "    kd_path=\"../Kd_2022/Kd_sentinel3_1h/Kd_sent3_20220801_20220901.nc\"\n",
    "\n",
    "    inputs_static=(\"/boisevol1/hpcshared/open_bay/hydro/full_res\"\n",
    "                   \"/wy2022_r52184/sfb_dfm/inputs-static/\")\n",
    "\n",
    "    swim_speeds=[-10.0/86400.0] # positive down, m/s\n",
    "    seg_function_resolution=500.0 # [m] resolution when discretizing spatiotemporal parameter to cartesian grid.\n",
    "    \n",
    "    def configure_general(self):\n",
    "        bloom_common.configure_dfm_t141798()\n",
    "                \n",
    "        self.mdu['output','WaqInterval']=\"\" # no need for DWAQ output\n",
    "        self.dfm_bin_dir=os.path.join(os.environ['DELFT_SRC'],'bin')\n",
    "        self.mpi_bin_dir=os.path.join(os.environ['DELFT_SRC'],'bin')\n",
    "\n",
    "        # Some files have moved around, so up date locations\n",
    "        self.mdu['output','CrsFile' ] = os.path.join(self.inputs_static, \"SB-observationcrosssection.pli\")\n",
    "        self.mdu['output','MapInterval' ] = 3600\n",
    "        \n",
    "        self.mdu['geometry','LandBoundaryFile'] = os.path.join(self.inputs_static,\"deltabay.ldb\")\n",
    "        self.mdu['geometry','FixedWeirFile'] = os.path.join(self.inputs_static,\"SBlevees_tdk.pli\")\n",
    "\n",
    "        del self.mdu['waves','WaveNikuradse']\n",
    "\n",
    "        if not self.temperature:\n",
    "            self.mdu['physics','Temperature'] = 0 # and fix-up tracers below\n",
    "            self.mdu['output','Wrimap_temperature'] = 0\n",
    "        # for non-restart this is handled by configure(), but restart doesn't call that.\n",
    "        if self.dwaq is True:                                                                                              \n",
    "            self.dwaq=dwaq.WaqOnlineModel(model=self)\n",
    "            \n",
    "    def set_bloom_tracers(self):\n",
    "        self.my_tracers=[]\n",
    "        \n",
    "        # I think the steps are\n",
    "        #  1. add the tracer definitions to forcing data via appending/updating FlowFMold_bnd.ext\n",
    "        #  2. add/overwrite the tracers in the restart file.\n",
    "        \n",
    "        tracers=[]\n",
    "\n",
    "        for swim_i,swim_speed in enumerate(self.swim_speeds): # positive down, m/s\n",
    "            # Names must be <=10 characters!\n",
    "            conc='conc' + str(swim_i)\n",
    "\n",
    "            def tracer_one(rst_ds,values_cell_layer):\n",
    "                values_cell_layer[:,:]=1.0\n",
    "            def tracer_zero(rst_ds,values_cell_layer):\n",
    "                values_cell_layer[:,:] = 0.0\n",
    "            tracers.append( dict(name=conc,func=tracer_one,fall_velocity_m_s=swim_speed))            \n",
    "\n",
    "        #for tracer in tracers:\n",
    "        #    # Initials don't really matter here as they are manually written to restart files.\n",
    "        #    self.dwaq.substances[tracer['name']]=dwaq.Substance(initial=0)\n",
    "            \n",
    "        self.my_tracers=tracers\n",
    "        # Adding the tracers to the ext file doesn't happen until copy_file_for_restart\n",
    "        # likewise, will have to modify the restart files later.\n",
    "\n",
    "    def update_restart_with_tracers(self):\n",
    "        def modify_ic(rst_ds,**kw):\n",
    "            for tracer in self.my_tracers:\n",
    "                name=tracer['name']\n",
    "                func=tracer['func']\n",
    "                self.log.info(f\"Setting tracer {name} in restart file\")\n",
    "                # mimic sa1 tracer\n",
    "                salt=rst_ds['sa1']\n",
    "                values=salt.values.copy() # ('time','nFlowElem','laydim')\n",
    "                values[...] = 0.0 # don't accidentally write salt data though\n",
    "                \n",
    "                # updates values in place.\n",
    "                func(rst_ds=rst_ds,values_cell_layer=values[0,:,:])\n",
    "                rst_ds[name]=salt.dims, values\n",
    "                for aname in ['coordinates','grid_mapping']:\n",
    "                    if aname in salt.attrs:\n",
    "                        rst_ds[name].attrs[aname]=salt.attrs[aname]\n",
    "        self.modify_restart_data(modify_ic)\n",
    "                \n",
    "    def add_tracers_to_bcs(self):\n",
    "        # take a more low-level approach compared to usual BC configuration\n",
    "        # so that we can be very careful about what things change.\n",
    "        ext_fn=self.mdu.filepath(('external forcing','ExtForceFile'))\n",
    "        orig_ext_fn=ext_fn+\".orig\"\n",
    "        shutil.copyfile(ext_fn,orig_ext_fn)\n",
    "\n",
    "        bcs=self.parse_old_bc(orig_ext_fn)\n",
    "        \n",
    "        new_tracer_names=[t['name'] for t in self.my_tracers]\n",
    "        configured_tracers={}\n",
    "        \n",
    "        # Try to make tracer BCs for new tracers 1 everywhere.\n",
    "        # This may have to be done more manually for flow and stage BCs.\n",
    "        # Note that establishing order here is very confusing. If these\n",
    "        # need to be nonzero, it will take some work to know\n",
    "        # it's correct. probably the strategy should be to filter out \n",
    "        # all existing BCs for these tracers, and then write them at the\n",
    "        # end in our prescribed order. This [I think] is what it does\n",
    "        # currently.\n",
    "        \n",
    "        new_bc_values=[1.0 for t in self.my_tracers]\n",
    "\n",
    "        def name_matches(cfg_name):\n",
    "            for tracer in tracers:\n",
    "                if tracer['name'].lower() == cfg_name.lower():\n",
    "                    if tracer['name']!=cfg_name:\n",
    "                        print(f\"Careful - case mismatch {cfg_name} vs {tracer['name']}\")\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        \n",
    "        with open(ext_fn,'wt') as fp_new:\n",
    "            bc_needing_tracer=[]\n",
    "            for rec in bcs:\n",
    "                write_verbatim=True\n",
    "\n",
    "                # HERE: Need to track discharge (flow) and stage BCs, then \n",
    "                # add tracer to those.\n",
    "                \n",
    "                quantity=rec['QUANTITY']\n",
    "                if quantity.upper().startswith('INITIALTRACER'):\n",
    "                    tracer_name=quantity[len(\"INITIALTRACER\"):]\n",
    "                    continue\n",
    "                elif quantity.upper().startswith('TRACERBND'):\n",
    "                    tracer_name=quantity[len(\"TRACERBND\"):]\n",
    "                    continue\n",
    "                elif ((not self.temperature) \n",
    "                      and \n",
    "                      (quantity.upper() in ['TEMPERATUREBND','INITIALTEMPERATURE',\n",
    "                                            'HUMIDITY_AIRTEMPERATURE_CLOUDINESS'])):\n",
    "                    continue\n",
    "                elif quantity.upper().startswith('DISCHARGE_SALINITY_TEMPERATURE_SORSIN'):\n",
    "                    print(\"Source/sink BC entry\")\n",
    "                    # Yuck - have to add or remove new column(s). This only involves rewriting \n",
    "                    # the data file,though. The stanza is unchanged.\n",
    "                    # Now that we drop temperature, I think orig_num_values goes from 3 to 2.\n",
    "                    if self.temperature:\n",
    "                        orig_num_values = 3\n",
    "                    else:\n",
    "                        orig_num_values = 2\n",
    "                    self.add_tracer_bcs(rec,new_values=new_bc_values,orig_num_values=orig_num_values)\n",
    "                elif quantity.upper() in ['DISCHARGEBND', 'WATERLEVELBND']:\n",
    "                    bc_needing_tracer.append(rec)                    \n",
    "\n",
    "                # At this point nobody ever changes the stanza, it's all written verbatim.\n",
    "                if write_verbatim:\n",
    "                    fp_new.write(\"\\n\".join(rec['stanza'])+\"\\n\")\n",
    "                    continue\n",
    "                \n",
    "            # And write out our new tracers (including ones that were skipped during \n",
    "            # transcription above\n",
    "            for tracer in self.my_tracers:\n",
    "                name=tracer['name']\n",
    "                ic_fn=f\"dummy-{name}.xyz\"\n",
    "                with open(os.path.join(self.run_dir,ic_fn),'wt') as fp_xyz:\n",
    "                    fp_xyz.write(\"550000 4180000 0.0\\n\")\n",
    "                fp_new.write(\"\\n# NEW TRACERS\\n\"\n",
    "                             f\"QUANTITY=initialtracer{name}\\n\"\n",
    "                             f\"FILENAME={ic_fn}\\n\"\n",
    "                             \"FILETYPE=7\\n\"\n",
    "                             \"METHOD=5\\n\"\n",
    "                             \"OPERAND=O\\n\")\n",
    "                \n",
    "                if tracer['fall_velocity_m_s']!=0.0:\n",
    "                    # Presumably DWAQ-based settling velocity works, too. But that would require\n",
    "                    # choosing tracers that already have a settling process associated with them,\n",
    "                    # or to code up a custom settling process. In contrast, if it works to \n",
    "                    # set constant settling here, where DFM handles it, things would be much simpler.\n",
    "                    \n",
    "                    self.log.warning(\"Hoping that fall velocity in can be set via DFM instead of DWAQ\")\n",
    "                    w=tracer['fall_velocity_m_s']\n",
    "                    fp_new.write(f\"TRACERFALLVELOCITY={w:.8f}\\n\")\n",
    "\n",
    "                for rec in bc_needing_tracer:\n",
    "                    # Copy geometry\n",
    "                    base_fn=os.path.basename(rec['FILENAME'])\n",
    "                    assert '.pli' in base_fn\n",
    "                    # Use basename because bc_files is shared.\n",
    "                    pli_fn = base_fn.replace('.pli',f\"-{name}.pli\")\n",
    "                    shutil.copyfile(os.path.join(self.run_dir,rec['FILENAME']),\n",
    "                                    os.path.join(self.run_dir,pli_fn))\n",
    "                    # Fabricate data\n",
    "                    tim_fn = pli_fn.replace('.pli','_0001.tim')\n",
    "                    with open(os.path.join(self.run_dir,tim_fn),'wt') as fp:\n",
    "                        # +-20 years around reference time. \n",
    "                        fp.write(\"-10000000.0 1.0\\n\")\n",
    "                        fp.write(\"10000000.0 1.0\\n\")\n",
    "\n",
    "                    stanza = [ \n",
    "                        f\"QUANTITY=tracerbnd{name}\",\n",
    "                        f\"FILENAME={pli_fn}\",\n",
    "                        \"FILETYPE=9\",\n",
    "                        \"METHOD=3\",\n",
    "                        \"OPERAND=O\"\n",
    "                    ]\n",
    "                    fp_new.write(\"\\n\".join(stanza) +\"\\n\")\n",
    "\n",
    "    def add_tracer_bcs(self,bc,new_values=[],orig_num_values=None):\n",
    "        \"\"\"\n",
    "        Add additional columns to a source/sink data file.\n",
    "        So if the new run will include two dwaq tracers, pass new_values=[0,1]\n",
    "        (which would tag sources with 0 for the first and 1.0 for the second)\n",
    "        orig_num_values: 3 for run with salinity and temperature. I think\n",
    "        less than that if temperature and/or salinity are disabled. \n",
    "        \"\"\"\n",
    "        if orig_num_values is None:\n",
    "            if self.temperature:\n",
    "                orig_num_values=3\n",
    "            else:\n",
    "                orig_num_values=2\n",
    "                \n",
    "        # yuck...\n",
    "        pli_fn=os.path.join(self.run_dir,bc['FILENAME'])\n",
    "        assert pli_fn.lower().endswith('.pli')\n",
    "        fn=pli_fn[:-4] + \".tim\"\n",
    "        assert os.path.exists(fn)\n",
    "        fn_orig=fn+\".orig\"\n",
    "        if not os.path.exists(fn_orig):\n",
    "            shutil.copyfile(fn,fn_orig)\n",
    "        data_orig=np.loadtxt(fn_orig)\n",
    "        # drop previous forcing for new tracers. leaving time column and the original Q,S,T values\n",
    "        columns=[data_orig[:,:1+orig_num_values]] \n",
    "        for new_val in new_values:\n",
    "            columns.append( np.full(data_orig.shape[0],new_val))\n",
    "        data=np.column_stack(columns)\n",
    "        np.savetxt(fn,data,fmt=\"%.6g\")\n",
    "\n",
    "    def fix_ext_paths(self):\n",
    "        # from run_dfm_rs_chl: Fix paths that have moved in external forcing file.\n",
    "        # And also in ext boundary file. \n",
    "        ext_fn=self.mdu.filepath(('external forcing','ExtForceFile'))\n",
    "        orig_ext_fn=ext_fn+\".orig\"\n",
    "        shutil.copyfile(ext_fn,orig_ext_fn)\n",
    "\n",
    "        print(f\"Trying to fix_ext_paths in {orig_ext_fn} => {ext_fn}\")\n",
    "        with open(orig_ext_fn,'rt') as fp_orig:\n",
    "            with open(ext_fn,'wt') as fp_new:\n",
    "                for line in fp_orig:\n",
    "                    m=re.match(r'\\s*filename\\s*=\\s*([^#]+)(#.*)?',line,re.I)\n",
    "                    if m:\n",
    "                        ext_entry = m.group(1).strip()\n",
    "                        print(f\"Checking on filename {ext_entry} in external forcing file\")\n",
    "                        # or should it be the original run directory instead of self.run_dir?\n",
    "                        real_path=os.path.abspath(os.path.join(self.run_dir,ext_entry))\n",
    "                        if not os.path.exists(real_path):\n",
    "                            # If it's from inputs-static replace\n",
    "                            if os.path.dirname(real_path).endswith('inputs-static'):\n",
    "                                real_path = os.path.join(self.inputs_static, os.path.basename(real_path))\n",
    "                                assert os.path.exists(real_path)\n",
    "                                line=f\"FILENAME={real_path}\\n\"\n",
    "                            else:\n",
    "                                raise Exception(\"redirect here\")\n",
    "                    fp_new.write(line)\n",
    "\n",
    "class DFMGPTracer: \n",
    "    # v00: old, dwaq based setup\n",
    "    # v01: online, dfm-based setup.\n",
    "    name=\"gp_tracers_v01\"\n",
    "    \n",
    "    # Will start from the end of this existing run (which doesn't have the tracers)\n",
    "    dfm_base_run_dir=\"dfm_spinup\"\n",
    "    \n",
    "    restart_copy_names=[\"source_files\"] # copy, because we end up modifying some\n",
    "\n",
    "    release_time = np.datetime64(\"2022-08-02\")\n",
    "    end_timeA = np.datetime64(\"2022-08-24 00:00\")\n",
    "    #end_timeB = np.datetime64(\"2022-08-30\")\n",
    "    \n",
    "    def run_to_A(self):\n",
    "        \"\"\"\n",
    "        Find a restart point <= release time. \n",
    "        initialize and run to end_timeA. \n",
    "        \"\"\"\n",
    "        prev_model=Model.load(self.dfm_base_run_dir)            \n",
    "        start_time=prev_model.restartable_time()\n",
    "        assert start_time < self.release_time,f\"Need to scan for restart time before last restart\"\n",
    "\n",
    "        # Setup a restart\n",
    "        model=prev_model.create_restart(deep=True) \n",
    "        model.run_stop=self.end_timeA\n",
    "\n",
    "        self.setup_and_run(model)\n",
    "\n",
    "    def run_A_to_B(self):\n",
    "        \"\"\"\n",
    "        Check for the most recent completed run ending at the release time.\n",
    "        None if not found.\n",
    "        Configure restart\n",
    "        \"\"\"\n",
    "        candidates = glob.glob(self.pattern_for_run_ending_at(self.end_timeA))\n",
    "        candidates.sort(reverse=True)\n",
    "        for candidate in candidates: \n",
    "            if Model.run_completed(candidate):\n",
    "                print(f\"Will use {candidate} as previous run\")\n",
    "                prev_model = Model.load(candidate)\n",
    "                break\n",
    "        else:\n",
    "            print(\"No completed runs end at time of release\")\n",
    "            return\n",
    "            \n",
    "        # Setup a restart\n",
    "        model=prev_model.create_restart(deep=True) \n",
    "        model.run_stop=self.end_timeB\n",
    "        self.setup_and_run(model)\n",
    "\n",
    "    def setup_and_run(self,model):\n",
    "        self.set_run_dir(model)\n",
    "        model.configure_general()\n",
    "        \n",
    "        # populates self.my_tracers as a list of dictionaries\n",
    "        # with ICs, names, etc.\n",
    "        model.set_bloom_tracers()\n",
    "            \n",
    "        # This alters the MDU, so do it before write()\n",
    "        model.update_restart_with_tracers()\n",
    "        model.write()\n",
    "        \n",
    "        # Can fix some things in ext forcing file now\n",
    "        model.fix_ext_paths()\n",
    "        # This updates the BC data in place. Do it here so that \n",
    "        # we have a starting ext file which will be updated with\n",
    "        # new tracers.\n",
    "        model.add_tracers_to_bcs()\n",
    "        model.partition()\n",
    "        model.run_simulation()\n",
    "            \n",
    "    run_dir_prefix=\"run\"\n",
    "    def set_run_dir(self,model):\n",
    "        start_str,stop_str=[ utils.to_datetime(t).strftime(\"%Y%m%dT%H%M\")\n",
    "                            for t in [model.run_start,model.run_stop]]\n",
    "        for x in range(20):\n",
    "            run_dir=os.path.join(self.name,f\"{self.run_dir_prefix}_{start_str}_{stop_str}_v{x:02}\")\n",
    "            if not os.path.exists(run_dir): break\n",
    "        else:\n",
    "            raise Exception(f\"Too many retries for {run_dir}\")\n",
    "        model.run_dir=run_dir\n",
    "        model.set_restart_file() # kludge. RestartFile needs run_dir.\n",
    "    def pattern_for_run_ending_at(self,end_time):\n",
    "        stop_str = utils.strftime(end_time,\"%Y%m%dT%H%M\")\n",
    "        return os.path.join(self.name,f\"{self.run_dir_prefix}_*_{stop_str}_v*\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f28c1312-b0c4-475f-86ce-fa55d4f198cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HydroModel:set_restart_file: Setting RestartFile based on self.restart_from\n",
      "INFO:HydroModel:set_restart_file: Setting RestartFile based on self.restart_from\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Updating RestartFile to wy2022_bloom_16layer_20220801_000000_rst.nc\n",
      "INFO:HydroModel:Could not find BC to get initial water level\n",
      "WARNING:HydroModel:SKIPPING self.set_restart_file()\n",
      "INFO:DFlowModel:Writing MDU to gp_tracers_v01/run_20220801T0000_20220824T0000_v02/wy2022_bloom_16layer.mdu\n",
      "INFO:HydroModel:Symlink gp_tracers_v01/run_20220801T0000_20220824T0000_v02/bc_files => ../../dfm_spinup/bc_files\n",
      "INFO:HydroModel:Copy dfm_spinup/source_files => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/source_files\n",
      "INFO:HydroModel:Symlink gp_tracers_v01/run_20220801T0000_20220824T0000_v02/meteo_coarse.grd => ../../dfm_spinup/meteo_coarse.grd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to fix_ext_paths in gp_tracers_v01/run_20220801T0000_20220824T0000_v02/FlowFMold_bnd.ext.orig => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/FlowFMold_bnd.ext\n",
      "Checking on filename bc_files/MARINS1_flow.pli in external forcing file\n",
      "Checking on filename bc_files/MARINS1_salt.pli in external forcing file\n",
      "Checking on filename bc_files/MARINS1_temp.pli in external forcing file\n",
      "Checking on filename bc_files/MARINS3_flow.pli in external forcing file\n",
      "Checking on filename bc_files/MARINS3_salt.pli in external forcing file\n",
      "Checking on filename bc_files/MARINS3_temp.pli in external forcing file\n",
      "Checking on filename bc_files/MARINS2_flow.pli in external forcing file\n",
      "Checking on filename bc_files/MARINS2_salt.pli in external forcing file\n",
      "Checking on filename bc_files/MARINS2_temp.pli in external forcing file\n",
      "Checking on filename bc_files/MARINN_flow.pli in external forcing file\n",
      "Checking on filename bc_files/MARINN_salt.pli in external forcing file\n",
      "Checking on filename bc_files/MARINN_temp.pli in external forcing file\n",
      "Checking on filename bc_files/PETALUMA_flow.pli in external forcing file\n",
      "Checking on filename bc_files/PETALUMA_salt.pli in external forcing file\n",
      "Checking on filename bc_files/PETALUMA_temp.pli in external forcing file\n",
      "Checking on filename bc_files/SONOMA_flow.pli in external forcing file\n",
      "Checking on filename bc_files/SONOMA_salt.pli in external forcing file\n",
      "Checking on filename bc_files/SONOMA_temp.pli in external forcing file\n",
      "Checking on filename bc_files/NAPA_flow.pli in external forcing file\n",
      "Checking on filename bc_files/NAPA_salt.pli in external forcing file\n",
      "Checking on filename bc_files/NAPA_temp.pli in external forcing file\n",
      "Checking on filename bc_files/SOLANOWa_flow.pli in external forcing file\n",
      "Checking on filename bc_files/SOLANOWa_salt.pli in external forcing file\n",
      "Checking on filename bc_files/SOLANOWa_temp.pli in external forcing file\n",
      "Checking on filename bc_files/SOLANOWb_flow.pli in external forcing file\n",
      "Checking on filename bc_files/SOLANOWb_salt.pli in external forcing file\n",
      "Checking on filename bc_files/SOLANOWb_temp.pli in external forcing file\n",
      "Checking on filename bc_files/SOLANOWc_flow.pli in external forcing file\n",
      "Checking on filename bc_files/SOLANOWc_salt.pli in external forcing file\n",
      "Checking on filename bc_files/SOLANOWc_temp.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAC2_flow.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAC2_salt.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAC2_temp.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAC3_flow.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAC3_salt.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAC3_temp.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAC1_flow.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAC1_salt.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAC1_temp.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAC4_flow.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAC4_salt.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAC4_temp.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAW2_flow.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAW2_salt.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAW2_temp.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAW3_flow.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAW3_salt.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAW3_temp.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAW1_flow.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAW1_salt.pli in external forcing file\n",
      "Checking on filename bc_files/CCOSTAW1_temp.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYN1_flow.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYN1_salt.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYN1_temp.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYN4_flow.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYN4_salt.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYN4_temp.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYN2_flow.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYN2_salt.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYN2_temp.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYN3_flow.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYN3_salt.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYN3_temp.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc6_flow.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc6_salt.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc6_temp.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc1_flow.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc1_salt.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc1_temp.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc5_flow.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc5_salt.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc5_temp.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc4_flow.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc4_salt.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc4_temp.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc3_flow.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc3_salt.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc3_temp.pli in external forcing file\n",
      "Checking on filename bc_files/UALAMEDA_flow.pli in external forcing file\n",
      "Checking on filename bc_files/UALAMEDA_salt.pli in external forcing file\n",
      "Checking on filename bc_files/UALAMEDA_temp.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYS_flow.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYS_salt.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYS_temp.pli in external forcing file\n",
      "Checking on filename bc_files/COYOTE_flow.pli in external forcing file\n",
      "Checking on filename bc_files/COYOTE_salt.pli in external forcing file\n",
      "Checking on filename bc_files/COYOTE_temp.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVCc_flow.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVCc_salt.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVCc_temp.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW5_flow.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW5_salt.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW5_temp.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW4_flow.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW4_salt.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW4_temp.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW3_flow.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW3_salt.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW3_temp.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW2_flow.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW2_salt.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW2_temp.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW1_flow.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW1_salt.pli in external forcing file\n",
      "Checking on filename bc_files/SCLARAVW1_temp.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb1_flow.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb1_salt.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb1_temp.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb3_flow.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb3_salt.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb3_temp.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb4_flow.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb4_salt.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb4_temp.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb6_flow.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb6_salt.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb6_temp.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb2_flow.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb2_salt.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb2_temp.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb7_flow.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb7_salt.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb7_temp.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb5_flow.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb5_salt.pli in external forcing file\n",
      "Checking on filename bc_files/PENINSULb5_temp.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc2_flow.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc2_salt.pli in external forcing file\n",
      "Checking on filename bc_files/EBAYCc2_temp.pli in external forcing file\n",
      "Checking on filename bc_files/USANLORZ_flow.pli in external forcing file\n",
      "Checking on filename bc_files/USANLORZ_salt.pli in external forcing file\n",
      "Checking on filename bc_files/USANLORZ_temp.pli in external forcing file\n",
      "Checking on filename source_files/tesoro.pli in external forcing file\n",
      "Checking on filename source_files/american.pli in external forcing file\n",
      "Checking on filename source_files/sasm.pli in external forcing file\n",
      "Checking on filename source_files/novato.pli in external forcing file\n",
      "Checking on filename source_files/sunnyvale.pli in external forcing file\n",
      "Checking on filename source_files/petaluma.pli in external forcing file\n",
      "Checking on filename source_files/rodeo.pli in external forcing file\n",
      "Checking on filename source_files/fs.pli in external forcing file\n",
      "Checking on filename source_files/valero.pli in external forcing file\n",
      "Checking on filename source_files/phillips66.pli in external forcing file\n",
      "Checking on filename source_files/vallejo.pli in external forcing file\n",
      "Checking on filename source_files/ebmud.pli in external forcing file\n",
      "Checking on filename source_files/san_mateo.pli in external forcing file\n",
      "Checking on filename source_files/sfo.pli in external forcing file\n",
      "Checking on filename source_files/palo_alto.pli in external forcing file\n",
      "Checking on filename source_files/sausalito.pli in external forcing file\n",
      "Checking on filename source_files/south_bayside.pli in external forcing file\n",
      "Checking on filename source_files/ddsd.pli in external forcing file\n",
      "Checking on filename source_files/burlingame.pli in external forcing file\n",
      "Checking on filename source_files/pinole.pli in external forcing file\n",
      "Checking on filename source_files/st_helena.pli in external forcing file\n",
      "Checking on filename source_files/yountville.pli in external forcing file\n",
      "Checking on filename source_files/benicia.pli in external forcing file\n",
      "Checking on filename source_files/millbrae.pli in external forcing file\n",
      "Checking on filename source_files/sonoma_valley.pli in external forcing file\n",
      "Checking on filename source_files/napa.pli in external forcing file\n",
      "Checking on filename source_files/cccsd.pli in external forcing file\n",
      "Checking on filename source_files/ebda.pli in external forcing file\n",
      "Checking on filename source_files/calistoga.pli in external forcing file\n",
      "Checking on filename source_files/central_marin.pli in external forcing file\n",
      "Checking on filename source_files/lg.pli in external forcing file\n",
      "Checking on filename source_files/west_county_richmond.pli in external forcing file\n",
      "Checking on filename source_files/chevron.pli in external forcing file\n",
      "Checking on filename source_files/sf_southeast.pli in external forcing file\n",
      "Checking on filename source_files/shell.pli in external forcing file\n",
      "Checking on filename source_files/mt_view.pli in external forcing file\n",
      "Checking on filename source_files/marin5.pli in external forcing file\n",
      "Checking on filename source_files/san_jose.pli in external forcing file\n",
      "Checking on filename source_files/south_sf.pli in external forcing file\n",
      "Checking on filename source_files/ch.pli in external forcing file\n",
      "Checking on filename source_files/treasure_island.pli in external forcing file\n",
      "Checking on filename bc_files/Jersey_flow.pli in external forcing file\n",
      "Checking on filename bc_files/Jersey_salt.pli in external forcing file\n",
      "Checking on filename bc_files/RioVista_flow.pli in external forcing file\n",
      "Checking on filename bc_files/RioVista_salt.pli in external forcing file\n",
      "Checking on filename bc_files/Sea_ssh.pli in external forcing file\n",
      "Checking on filename bc_files/Sea_salt.pli in external forcing file\n",
      "Checking on filename /chicagovol1/hpcshared/open_bay/hydro/full_res/wy2022_bloom/sfb_dfm/inputs-static/friction12e.xyz in external forcing file\n",
      "Checking on filename precip_evap.tim in external forcing file\n",
      "Checking on filename bc_files/wind_linear_WY2022_bloom.amu in external forcing file\n",
      "Checking on filename bc_files/wind_linear_WY2022_bloom.amv in external forcing file\n",
      "Checking on filename bc_files/hac_linear_wind_2022_bloom.tem in external forcing file\n",
      "Checking on filename Salinity-topini.xyz in external forcing file\n",
      "Checking on filename Temperature-topini.xyz in external forcing file\n",
      "Checking on filename bc_files/sea_temp_ROMS.pli in external forcing file\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:HydroModel:Hoping that fall velocity in can be set via DFM instead of DWAQ\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0000_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0000_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0001_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0001_net.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top of partition: num_procs=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0002_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0002_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0003_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0003_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0004_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0004_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0005_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0005_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0006_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0006_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0007_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0007_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0008_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0008_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0009_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0009_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0010_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0010_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0011_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0011_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0012_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0012_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0013_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0013_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0014_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0014_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: dfm_spinup/sfei_v20_0015_net.nc => gp_tracers_v01/run_20220801T0000_20220824T0000_v02/sfei_v20_0015_net.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to call ['/opt/anaconda3/envs/dfm_t141798/bin/generate_parallel_mdu.sh', 'wy2022_bloom_16layer.mdu', '16', '6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HydroModel:Running command: /opt/anaconda3/envs/dfm_t141798/bin/mpiexec -n 16 /opt/anaconda3/envs/dfm_t141798/bin/dflowfm -t 1 --autostartstop wy2022_bloom_16layer.mdu\n"
     ]
    }
   ],
   "source": [
    "groto=DFMGPTracer()\n",
    "\n",
    "groto.run_to_A()\n",
    "#groto.run_A_to_B()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2809a992-7c91-4262-ad40-0099c8695dd2",
   "metadata": {},
   "source": [
    "Old Code Below Here\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c0c67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hydro_name(hydro): return \"wy2022_take2\"\n",
    "\n",
    "def configure_dwaq(): # May be outdated, esp. for chicago.\n",
    "    # configure DWAQ:\n",
    "    DELFT_SRC=\"/opt/software/delft/delwaq/precompiled_binaries/DFM1.6.2.49199/lnx64\"\n",
    "    #DELFT_SRC=\"/home/alliek/software/Delft3D-FM/64634\"\n",
    "    DELFT_SHARE=os.path.join(DELFT_SRC,\"share\",\"delft3d\")\n",
    "    DELFT_LIB=os.path.join(DELFT_SRC,\"lib\")\n",
    "\n",
    "    os.environ['DELFT_SRC']=DELFT_SRC\n",
    "    os.environ['DELFT_SHARE']=DELFT_SHARE\n",
    "    \n",
    "    if 'LD_LIBRARY_PATH' in os.environ:\n",
    "        os.environ['LD_LIBRARY_PATH']=DELFT_LIB+\":\"+os.environ['LD_LIBRARY_PATH']\n",
    "    else:\n",
    "        os.environ['LD_LIBRARY_PATH']=DELFT_LIB\n",
    "\n",
    "configure_dwaq()\n",
    "dfm_bin=os.path.join(os.environ['DELFT_SRC'],'bin')\n",
    "waqpbexport=os.path.join(dfm_bin,'waqpbexport')\n",
    "waqpbimport=os.path.join(dfm_bin,'waqpbimport')\n",
    "\n",
    "class CommonSetup(object):\n",
    "    \"\"\"\n",
    "    Common code for various tracers runs\n",
    "    \"\"\"\n",
    "    name='common' # should overload\n",
    "    hydro=None\n",
    "    base_path=None # must be set!\n",
    "\n",
    "    force=True # whether to allow re-using an existing run\n",
    "    \n",
    "    # start time offset from start of hydro by this delta\n",
    "    # give it some decent spinup time\n",
    "    start_time=np.datetime64(\"2022-08-10 00:00\")\n",
    "    \n",
    "    # set length of the run. Appears to be the end of valid output, even though the\n",
    "    # hydro reports going until the 25th.\n",
    "    stop_time=np.datetime64(\"2022-08-22 23:00\") # seems that even temperature run is dicey on last step\n",
    "    \n",
    "    integration_option=\"15.60\" # if set, copied to WaqModel\n",
    "    time_step=3000\n",
    "    map_time_step=3000 # otherwise it will default to time_step, which could be really short.    \n",
    "\n",
    "    waq_kws={}\n",
    "    def __init__(self,**kw):\n",
    "        utils.set_keywords(self,kw)   \n",
    "        if self.base_path is None:\n",
    "            self.base_path=self.calc_base_path()\n",
    "                \n",
    "            yyyymmdd=utils.to_datetime(self.start_time).strftime('%Y%m%d')\n",
    "            self.base_path+=\"_%s\"%(yyyymmdd)   \n",
    "            \n",
    "            # And make it unique on successive runs\n",
    "            for seq in range(50):\n",
    "                test_path=self.base_path\n",
    "                if seq>0:\n",
    "                    test_path+=f\"-v{seq:03}\"\n",
    "                if not os.path.exists(test_path):\n",
    "                    self.base_path=test_path\n",
    "                    break\n",
    "            else:\n",
    "                raise Exception(\"Too many runs with same name\")\n",
    "            \n",
    "            log.info(\"base_path defaults to %s\"%self.base_path)\n",
    "    def calc_base_path(self):\n",
    "        p='run_%s_%s'%(hydro_name(self.hydro),self.name)\n",
    "        return p\n",
    "        \n",
    "    def release_conc_3d(self,*a,**kw):\n",
    "        C_2d=self.release_conc_2d(*a,**kw)\n",
    "        C_3d=self.hydro.extrude_element_to_segment(C_2d)\n",
    "        return C_3d\n",
    "\n",
    "    def setup_model(self):\n",
    "        # Create a WaqModel, add some tracers\n",
    "        self.wm=wm=dwaq.WaqModel(hydro=self.hydro,\n",
    "                                 overwrite=True,\n",
    "                                 base_path=self.base_path,\n",
    "                                 mon_time_step=1000000, # daily\n",
    "                                 time_step=self.time_step,\n",
    "                                 **self.waq_kws)\n",
    "        # add some option for balances.\n",
    "        wm.integration_option=\"%s BALANCES-OLD-STYLE BAL_NOLUMPPROCESSES BAL_NOLUMPLOADS BAL_NOLUMPTRANSPORT\"%self.integration_option\n",
    "        #wm.start_time+= self.start_offset\n",
    "        wm.start_time = self.start_time # may have to be smarter about starting on an output time step.\n",
    "        # hydro reports the wrong stop time. manually set.\n",
    "        if self.stop_time is not None:\n",
    "            wm.stop_time=self.stop_time\n",
    "        \n",
    "        self.setup_tracers()\n",
    "        \n",
    "        wm.parameters['ACTIVE_VertDisp']=1\n",
    "        wm.parameters['ScaleVDisp']=1.0 \n",
    "        \n",
    "    def run_waq_model(self):\n",
    "        assert self.base_path is not None,\"Must specify base_path\"\n",
    "        \n",
    "        if not self.force:\n",
    "            if os.path.exists(os.path.join(self.base_path,'dwaq_map.nc')):\n",
    "                log.info(\"Run seems to exist -- will not run again\")\n",
    "                self.wm=dwaq.WaqModel.load(self.base_path,load_hydro=False)\n",
    "                return\n",
    "\n",
    "        self.setup_model()\n",
    "        \n",
    "        wm=self.wm\n",
    "        wm.cmd_write_hydro()\n",
    "        wm.cmd_write_inp()\n",
    "        self.copy_notebook()        \n",
    "        wm.cmd_delwaq1()\n",
    "        wm.cmd_delwaq2()\n",
    "        wm.cmd_write_nc()\n",
    "    def copy_notebook(self):\n",
    "        script_fn=\"run_transport_and_swimming_v00.ipynb\"\n",
    "        shutil.copyfile(script_fn,os.path.join(self.base_path,script_fn))\n",
    "    def setup_tracer_continuity(self):\n",
    "        # continuity tracer:\n",
    "        self.wm.substances['continuity']=dwaq.Substance(initial=1.0)\n",
    "        # This adds a concentration=1.0 boundary condition on all the boundaries.\n",
    "        all_bcs=[b.decode() for b in np.unique(self.hydro.boundary_defs()['type'])]\n",
    "        self.wm.add_bc(all_bcs,'continuity',1.0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e134b73d",
   "metadata": {},
   "source": [
    "Custom processes\n",
    "--\n",
    "\n",
    "This is the low-level approach. There may be some Delft tools to automate this, but\n",
    "my general experience is that the tools get out of date and become unsupported.\n",
    "\n",
    "Each process needs two pieces:\n",
    " 1. Fortran code that implements the operation\n",
    " 2. Tables that associate a process name, inputs, and outputs with the fortran function.\n",
    " \n",
    "The same fortran code is reused for similar processes. The tables can define multiple\n",
    "entries that use the same fortran implementation.\n",
    "\n",
    "This means there is the \"simple\" level of customizing processes (edit the tables), and\n",
    "the \"complete\" level (write new fortran code, along with tables to use the new fortran\n",
    "subroutine).\n",
    "\n",
    "Compiling new fortran subroutines requires using a compiler similar to what was used to\n",
    "compile the original delwaq library. I think Deltares tend to use intel compilers, and\n",
    "intel compilers are generally compatible with gnu compilers, so this isn't necessarily\n",
    "a major hurdle (and intel compilers are readily available for free now). Nonetheless,\n",
    "getting everything to work with a bespoke fortran subroutine is more error-prone than\n",
    "just editing the tables.\n",
    "\n",
    "The tables are stored three different ways, which makes the editing process at first\n",
    "confusing.\n",
    " - proc_def.def and proc_def.dat: binary (NEFIS), read by delwaq at runtime\n",
    " - proces.asc: the human (for some value of human) readable table\n",
    " - a bunch of CSV files\n",
    " \n",
    "You'd want to just edit proces.asc, and generate proc_def.*, but no. You have to edit\n",
    "proces.asc, convert that to CSV (`waqpbimport`), and then convert back (`waqpbexport`).\n",
    "Also, even though `waqpbimport` updates the CSV files, it requires them to already\n",
    "exist.\n",
    "\n",
    "You'd expect that binary distribution of delwaq would come with the CSVs, but no.\n",
    "\n",
    "\n",
    "So this process is tricky with a binary compile, even if you don't want to compile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "608db046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantaneous release, just see how the blob moves.\n",
    "# Rather than using \"anonymous\" tracers as in the age tracer code, easier \n",
    "# to use substances that already have settling defined, but with no\n",
    "# other processes. Use AlgNN tracers since there are lots of them.\n",
    "\n",
    "class SwimmingEverywhere(CommonSetup):\n",
    "    swim_speeds=[0,-5.0,-15.0,-30,-50] # positive down.\n",
    "    start_time=np.datetime64(\"2022-08-01 00:00\")\n",
    "    stop_time=np.datetime64(\"2022-08-31 00:00\") \n",
    "    kd_path=\"../Kd_2022/Kd_sentinel3_1h/Kd_sent3_20220801_20220901.nc\"\n",
    "    \n",
    "    def setup_tracers(self):\n",
    "        self.add_light()\n",
    "        \n",
    "        all_bcs=[b.decode() for b in np.unique(self.hydro.boundary_defs()['type'])]\n",
    "\n",
    "        for swim_i,speed in enumerate(self.swim_speeds):\n",
    "            #name=f'IM{swim_i+1}'\n",
    "            name=f'Alg{swim_i+1:02d}'\n",
    "            conc=f'BLOOM' + name\n",
    "            # initial condition of 1.0\n",
    "            unity=1.0\n",
    "            self.wm.substances[conc]=dwaq.Substance(initial=unity)\n",
    "            self.wm.parameters['VSed' + name]=  speed             \n",
    "            self.wm.add_process('SED' + name)        \n",
    "            \n",
    "            # This adds a concentration=1.0 boundary condition on all the boundaries.\n",
    "            self.wm.add_bc(all_bcs,conc,unity)\n",
    "\n",
    "        self.wm.parameters['TaucS']=0.0 # no deposition - covers all algae.\n",
    "        \n",
    "    def add_light(self):\n",
    "        if self.kd_path is None: return\n",
    "        self.add_kd()\n",
    "        self.wm.add_process(name='CalcRad')\n",
    "        self.add_insolation()\n",
    "        \n",
    "        self.wm.map_output += ('RadSurf','Rad', 'RadBot','ExtVl')\n",
    "        \n",
    "    def add_insolation(self):\n",
    "        cimis=xr.open_dataset('/richmondvol1/hpcshared/inputs/cimis/union_city-hourly-2022_bloom.nc')\n",
    "        # Starts as PST, but the model is UTC.\n",
    "        cimis=cimis.set_coords('time').swap_dims({'Date':'time'})\n",
    "        cimis['time']=cimis['time']+np.timedelta64(8,'h')\n",
    "        sol_rad=cimis['HlySolRad'].values\n",
    "        sol_rad=utils.fill_invalid(sol_rad)\n",
    "\n",
    "        t0=np.datetime64(self.hydro.time0)\n",
    "        t_secs=((cimis.time.values-t0)/np.timedelta64(1,'s')).astype(np.int64)\n",
    "        param=dwaq.ParameterTemporal(times=t_secs,values=sol_rad)\n",
    "        self.wm.parameters['RadSurf'] = param\n",
    "            \n",
    "    def add_kd(self):\n",
    "        # extrude to 3D, write seg function\n",
    "        ds=xr.open_dataset(self.kd_path)\n",
    "        g=unstructured_grid.UnstructuredGrid.read_ugrid(ds)\n",
    "        assert np.allclose(g.cells_centroid(), self.hydro.grid().cells_centroid()),\"Kd field grid does not match\"\n",
    "\n",
    "        t0=np.datetime64(self.hydro.time0)\n",
    "        tsecs=(ds.time.values-t0)/np.timedelta64(1,'s')\n",
    "        def seg_func(t):\n",
    "            C_2d=ds['Kd'].sel(time=t0+t*np.timedelta64(1,'s'),method='nearest').values\n",
    "            return self.hydro.extrude_element_to_segment(C_2d)\n",
    "            \n",
    "        # No self-shading, specify overall extinction directly\n",
    "        self.wm.parameters['ExtVl'] = dwaq.ParameterSpatioTemporal(times=tsecs,func_t=seg_func)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4339dc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:base_path defaults to run_wy2022_take2_common_20220801-v006\n",
      "INFO:WaqModel: start time updated from hydro: 2022-05-01T00:00:00.000000\n",
      "INFO:WaqModel: stop time update from hydro: 2022-10-01T00:00:00.000000\n",
      "INFO:HydroFiles:Segment depth will be inferred\n",
      "INFO:WaqModel:Parameters gleaned from hydro: NamedObjects([('surf', <stompy.model.delft.waq_scenario.ParameterSpatial object at 0x7f97fff29c40>), ('bottomdept', <stompy.model.delft.waq_scenario.ParameterSpatial object at 0x7f97fff7df70>), ('vertdisper', <stompy.model.delft.waq_scenario.ParameterSpatioTemporal object at 0x7f97f5ff2400>), ('tau', <stompy.model.delft.waq_scenario.ParameterSpatioTemporal object at 0x7f97f5ff2dc0>), ('temp', <stompy.model.delft.waq_scenario.ParameterSpatioTemporal object at 0x7f97f5ff2a60>), ('salinity', <stompy.model.delft.waq_scenario.ParameterSpatioTemporal object at 0x7f97f5ff2250>)])\n",
      "INFO:WaqModel:Writing hydro data\n",
      "INFO:HydroFiles:Using .bnd file, not writing out kludgey boundary-links.csv\n",
      "INFO:HydroFiles:Writing hyd file\n",
      "INFO:HydroFiles:Segment depth will be inferred\n",
      "INFO:HydroFiles:Segment depth will be inferred\n",
      "INFO:HydroFiles:Writing srf file\n",
      "INFO:HydroFiles:Writing hydro parameters\n",
      "WARNING:HydroFiles:Exchange length file lazily reports 0 exchanges\n",
      "INFO:InpFile:No dispersion arrays, will skip assignment to substances\n",
      "INFO:InpFile:No velocity arrays, will skip assignment to substances\n",
      "INFO:WaqModel:write_supporting: writing 721 of 744 timesteps.\n",
      "INFO:WaqModel:Running delwaq1:\n",
      "INFO:WaqModel:  /opt/software/delft/delwaq/precompiled_binaries/DFM1.6.2.49199/lnx64/bin/delwaq1 -waq  -p /opt/software/delft/delwaq/precompiled_binaries/DFM1.6.2.49199/lnx64/share/delft3d/proc_def\n",
      "INFO:WaqModel:delwaq1 ran in 7.47s\n",
      "INFO:WaqModel:Running delwaq2 - might take a while...\n",
      "INFO:WaqModel:  /opt/software/delft/delwaq/precompiled_binaries/DFM1.6.2.49199/lnx64/bin/delwaq2 waqmodel\n",
      "INFO:WaqModel:Waiting for run_wy2022_take2_common_20220801-v006/waqmodel.mon to be created\n",
      "INFO:WaqModel:Okay - run_wy2022_take2_common_20220801-v006/waqmodel.mon exists now\n",
      "INFO:WaqModel:0.00% Completed\n",
      "INFO:WaqModel:3.33% Completed\n",
      "INFO:WaqModel:Time remaining: 4.184h (Sun Feb 12 23:31:23 2023) 166.35x realtime\n",
      "INFO:WaqModel:6.67% Completed\n",
      "INFO:WaqModel:Time remaining: 4.071h (Sun Feb 12 23:33:25 2023) 165.06x realtime\n",
      "INFO:WaqModel:10.00% Completed\n",
      "INFO:WaqModel:Time remaining: 3.928h (Sun Feb 12 23:33:33 2023) 164.97x realtime\n",
      "INFO:WaqModel:13.33% Completed\n",
      "INFO:WaqModel:Time remaining: 3.773h (Sun Feb 12 23:32:49 2023) 165.40x realtime\n",
      "INFO:WaqModel:16.67% Completed\n",
      "INFO:WaqModel:Time remaining: 3.604h (Sun Feb 12 23:31:06 2023) 166.46x realtime\n",
      "INFO:WaqModel:20.00% Completed\n",
      "INFO:WaqModel:Time remaining: 3.429h (Sun Feb 12 23:28:39 2023) 167.99x realtime\n",
      "INFO:WaqModel:23.33% Completed\n",
      "INFO:WaqModel:Time remaining: 3.262h (Sun Feb 12 23:26:53 2023) 169.21x realtime\n",
      "INFO:WaqModel:26.67% Completed\n",
      "INFO:WaqModel:Time remaining: 3.107h (Sun Feb 12 23:25:58 2023) 169.93x realtime\n",
      "INFO:WaqModel:30.00% Completed\n",
      "INFO:WaqModel:Time remaining: 2.959h (Sun Feb 12 23:25:30 2023) 170.35x realtime\n",
      "INFO:WaqModel:33.33% Completed\n",
      "INFO:WaqModel:Time remaining: 2.817h (Sun Feb 12 23:25:35 2023) 170.43x realtime\n",
      "INFO:WaqModel:36.67% Completed\n",
      "INFO:WaqModel:Time remaining: 2.679h (Sun Feb 12 23:26:10 2023) 170.19x realtime\n",
      "INFO:WaqModel:40.00% Completed\n",
      "INFO:WaqModel:Time remaining: 2.545h (Sun Feb 12 23:27:04 2023) 169.73x realtime\n",
      "INFO:WaqModel:43.33% Completed\n",
      "INFO:WaqModel:Time remaining: 2.412h (Sun Feb 12 23:28:05 2023) 169.14x realtime\n",
      "INFO:WaqModel:46.67% Completed\n",
      "INFO:WaqModel:Time remaining: 2.278h (Sun Feb 12 23:28:56 2023) 168.57x realtime\n",
      "INFO:WaqModel:50.00% Completed\n",
      "INFO:WaqModel:Time remaining: 2.142h (Sun Feb 12 23:29:42 2023) 168.03x realtime\n",
      "INFO:WaqModel:53.33% Completed\n",
      "INFO:WaqModel:Time remaining: 2.005h (Sun Feb 12 23:30:16 2023) 167.57x realtime\n",
      "INFO:WaqModel:56.67% Completed\n",
      "INFO:WaqModel:Time remaining: 1.866h (Sun Feb 12 23:30:44 2023) 167.18x realtime\n",
      "INFO:WaqModel:60.00% Completed\n",
      "INFO:WaqModel:Time remaining: 1.725h (Sun Feb 12 23:30:35 2023) 166.99x realtime\n",
      "INFO:WaqModel:63.33% Completed\n",
      "INFO:WaqModel:Time remaining: 1.580h (Sun Feb 12 23:29:49 2023) 167.05x realtime\n",
      "INFO:WaqModel:66.67% Completed\n",
      "INFO:WaqModel:Time remaining: 1.434h (Sun Feb 12 23:28:42 2023) 167.34x realtime\n",
      "INFO:WaqModel:70.00% Completed\n",
      "INFO:WaqModel:Time remaining: 1.288h (Sun Feb 12 23:27:47 2023) 167.73x realtime\n",
      "INFO:WaqModel:73.33% Completed\n",
      "INFO:WaqModel:Time remaining: 1.142h (Sun Feb 12 23:26:59 2023) 168.15x realtime\n",
      "INFO:WaqModel:76.67% Completed\n",
      "INFO:WaqModel:Time remaining: 0.996h (Sun Feb 12 23:26:18 2023) 168.58x realtime\n",
      "INFO:WaqModel:80.00% Completed\n",
      "INFO:WaqModel:Time remaining: 0.852h (Sun Feb 12 23:25:53 2023) 168.98x realtime\n",
      "INFO:WaqModel:83.33% Completed\n",
      "INFO:WaqModel:Time remaining: 0.709h (Sun Feb 12 23:25:33 2023) 169.33x realtime\n",
      "INFO:WaqModel:86.67% Completed\n",
      "INFO:WaqModel:Time remaining: 0.566h (Sun Feb 12 23:25:20 2023) 169.64x realtime\n",
      "INFO:WaqModel:90.00% Completed\n",
      "INFO:WaqModel:Time remaining: 0.424h (Sun Feb 12 23:25:20 2023) 169.88x realtime\n",
      "INFO:WaqModel:93.33% Completed\n",
      "INFO:WaqModel:Time remaining: 0.282h (Sun Feb 12 23:25:29 2023) 170.05x realtime\n",
      "INFO:WaqModel:96.67% Completed\n",
      "INFO:WaqModel:Time remaining: 0.141h (Sun Feb 12 23:25:39 2023) 170.17x realtime\n",
      "INFO:WaqModel:100.00% Completed\n",
      "INFO:WaqModel:Time remaining: 0.000h (Sun Feb 12 23:25:46 2023) 170.25x realtime\n",
      "INFO:WaqModel:delwaq2 ran in 15930.66s\n",
      "INFO:WaqModel:Done\n",
      "INFO:WaqModel:NEFIS file didn't exist. Skipping ugrid_nef()\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    pb=SwimmingEverywhere(hydro=hydro)\n",
    "\n",
    "    pb.run_waq_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
