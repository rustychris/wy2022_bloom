{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdc68395",
   "metadata": {},
   "source": [
    "Age / Exposure Tracers for Bloom Analysis\n",
    "==\n",
    "\n",
    "This is a retake on the early analysis of DWAQ-based tracers, but using an\n",
    "online-coupled DFM run.\n",
    "\n",
    "v02: Add temperature back in, initialized from AVHRR.\n",
    "\n",
    "First go revealed that\n",
    "* the ocean BC is likely too cold due to forcing from ROMS depth-averaged\n",
    "  temperature and grid-geometry related instability that gives ocean BC undue influence.\n",
    "* Air temperature forcing is too variable at daily time scales and too warm.\n",
    "\n",
    "Replaced ocean BC from ROMS with data from NDBC SF Buoy\n",
    "\n",
    "\n",
    "\n",
    "Notes from v01:\n",
    "The 2022-08-04 to 2022-08-30 run took 2.2 days, about 11x realtime.\n",
    "This version includes upward swimming at 0, 10, and 20 m/d, and disables temperature.\n",
    "\n",
    "Trying for bloom_tracer_v08, and all ranks get \"flownode mismatches\". Vague recollection that \n",
    "this can be caused by renumbering changes between the run being restarted and the new run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c99424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/richmondvol1/rusty/stompy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e3b33b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, shutil\n",
    "import datetime\n",
    "import six\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from stompy.spatial import field, proj_utils\n",
    "from stompy import utils\n",
    "from stompy.plot import plot_wkb, plot_utils\n",
    "import xarray as xr\n",
    "import stompy.plot.cmap as scmap\n",
    "from scipy import ndimage\n",
    "\n",
    "import stompy.model.delft.dflow_model as dfm\n",
    "import stompy.model.delft.waq_scenario as dwaq\n",
    "import stompy.model.delft.io as dio\n",
    "\n",
    "from stompy.model import unstructured_diffuser\n",
    "from stompy.grid import unstructured_grid\n",
    "from stompy.io.local import noaa_coops\n",
    "from shapely import geometry\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8483750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bloom_common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f163ecbe",
   "metadata": {},
   "source": [
    "DFM-based Runs\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548873c9-8788-48f9-b407-03ce53d3e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart files every 10 days, plus a restart file on 2022-08-01.\n",
    "# speed was 85x realtime on 16 cores.\n",
    "# Forcing should all be okay to copy/link for restarts.\n",
    "\n",
    "if 0: # Check on map and rst output:\n",
    "    dfm_base_run_dir=\"dfm_spinup\"\n",
    "    map_fn=os.path.join(dfm_base_run_dir,\n",
    "                        \"DFM_OUTPUT_wy2022_bloom_16layer\",\n",
    "                        \"wy2022_bloom_16layer_0000_20220501_000000_map.nc\")\n",
    "    rst_fn=os.path.join(dfm_base_run_dir,\n",
    "                        \"DFM_OUTPUT_wy2022_bloom_16layer\",\n",
    "                        \"wy2022_bloom_16layer_0000_20220801_000000_rst.nc\")\n",
    "    \n",
    "    map_ds=xr.open_dataset(map_fn)\n",
    "    rst_ds=xr.open_dataset(rst_fn)\n",
    "\n",
    "    grid = unstructured_grid.UnstructuredGrid.read_dfm(\"dfm_spinup/sfei_v20_net.nc\")\n",
    "    shore_poly = grid.boundary_polygon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47297cd0-5404-4452-9209-91050ae39274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing:\n",
    "#grid = unstructured_grid.UnstructuredGrid.read_dfm(\"dfm_spinup/sfei_v20_net.nc\")\n",
    "#run_start = np.datetime64(\"2022-08-02 12:00\")\n",
    "\n",
    "def get_temperature_on_grid_avhrr(grid, run_start, temp_database=\"RS_temperature/extrapolated_avhrr.nc\"):\n",
    "    ds=xr.open_dataset(temp_database)\n",
    "    \n",
    "    from stompy.spatial import field\n",
    "    tidx1=np.searchsorted(ds.time.values, run_start)\n",
    "    \n",
    "    if tidx1>0:\n",
    "        tidx0=tidx1-1\n",
    "        alpha = (run_start - ds.time.values[tidx0])/(ds.time.values[tidx1]-ds.time.values[tidx0])\n",
    "        F = ( (1-alpha)*ds.extrap_spatiotemporal_mu.isel(time=tidx0).values\n",
    "               + alpha*ds.extrap_spatiotemporal_mu.isel(time=tidx1).values)\n",
    "    else:\n",
    "        F = ds.extrap_spatiotemporal_mu.isel(time=tidx1).values\n",
    "        \n",
    "    fld=field.SimpleGrid(extents=[ds.longitude.values.min(), ds.longitude.values.max(),\n",
    "                                  ds.latitude.values.min(), ds.latitude.values.max()],\n",
    "                         F=F)\n",
    "    grid_ll = proj_utils.mapper('EPSG:26910','WGS84')(grid.cells_centroid())\n",
    "    grid_ll[:,0] += 360.0 # positive west longitude\n",
    "    F_on_grid=fld(grid_ll)\n",
    "\n",
    "    #  use grid diffusion to fill in gaps.\n",
    "    ud = unstructured_diffuser.Diffuser(grid)\n",
    "    for c in np.nonzero(np.isfinite(F_on_grid))[0]:\n",
    "        ud.set_dirichlet(F_on_grid[c],cell=c)\n",
    "    F_filled = ud.compute()\n",
    "\n",
    "    return F_filled\n",
    "\n",
    "def get_temperature_on_grid_acspo(grid, run_start, temp_database=\"RS_temperature/supercollated_data_v00.nc\"):\n",
    "    # database assumed to be in lat/lon, grid in UTM.\n",
    "    ds=xr.open_dataset(temp_database)\n",
    "        \n",
    "    tidx1=utils.nearest(ds.time.values, run_start) # both UTC. database is daily composite, centered on 12:00\n",
    "\n",
    "    if ds.latitude.values[1] < ds.latitude.values[0]:\n",
    "        lat_slice=slice(None,None,-1)\n",
    "    else:\n",
    "        lat_slice=slice(None)\n",
    "    F = ds.sea_surface_temperature.isel(time=tidx1,latitude=lat_slice).values\n",
    "    fld=field.SimpleGrid(extents=[ds.longitude.values.min(), ds.longitude.values.max(),\n",
    "                                  ds.latitude.values.min(), ds.latitude.values.max()],\n",
    "                         F=F)\n",
    "    grid_ll = proj_utils.mapper('EPSG:26910','WGS84')(grid.cells_centroid())\n",
    "    if ds.longitude.values.min()>0 and grid_ll[:,0].min()<0:\n",
    "        grid_ll[:,0] += 360.0 # positive west longitude\n",
    "    F_on_grid=fld.interpolate(grid_ll,interpolation='nearest')\n",
    "\n",
    "    #  use grid diffusion to fill in gaps.\n",
    "    ud = unstructured_diffuser.Diffuser(grid)\n",
    "    for c in np.nonzero(np.isfinite(F_on_grid))[0]:\n",
    "        ud.set_dirichlet(F_on_grid[c],cell=c)\n",
    "    F_filled = ud.compute()\n",
    "\n",
    "    return F_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b836c0e-39d5-4f3e-aae3-00531c548428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SF Buoy data for ocean BC:\n",
    "# 46062 is SF buoy - water temp, no air temp\n",
    "# 46237 is SF Bar - water and air temp\n",
    "\n",
    "# regular NOAA station for Richmond - 9414863 \n",
    "# Also check Port Chicago for air temp\n",
    "def sf_buoy_data():\n",
    "    # returns xr.DataArray for water temperature with a time dimension \n",
    "    url=\"https://www.ndbc.noaa.gov/view_text_file.php?filename=46026h2022.txt.gz&dir=data/historical/stdmet/\"\n",
    "    sf_buoy_cache = \"cache/sf_buoy_2022.csv\"\n",
    "    utils.download_url(url, local_file = sf_buoy_cache, on_abort='remove')\n",
    "    \n",
    "    from stompy.io.local import ndbc\n",
    "    six.moves.reload_module(ndbc)\n",
    "    sf_buoy = ndbc.parse_txt(sf_buoy_cache)\n",
    "    sf_buoy['WTMP'] = utils.fill_invalid(sf_buoy.WTMP.values)\n",
    "    da = sf_buoy.set_index('time')['WTMP'].to_xarray()\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d15fd2c7-17e1-4aab-9d4b-52c8726c09dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace met forcing - I don't have other humidity or cloudiness data, so will just\n",
    "# overwrite the temperature field.\n",
    "run_dir=\"bloom_tracers_v03/run_20220801T0000_20220802T1200_v00\"\n",
    "\n",
    "original_met = os.path.join(run_dir,'bc_files','hac_linear_wind_2022_bloom.tem')\n",
    "\n",
    "class MetUpdater:\n",
    "    noaa_air_stations=[ 9414750, # Alameda\n",
    "                        9414290, # SF Fort Point\n",
    "                        9414863, # Richmond\n",
    "                        9414523, # Redwood City\n",
    "                        9415141, # Davis Point (near Carquinez Br)\n",
    "                        #9415020, # Point Reyes\n",
    "                      ]\n",
    "    noaa_station_names={9414750:\"Alameda\",\n",
    "                        9414290:\"SF Fort Point\",\n",
    "                        9414863:\"Richmond\",\n",
    "                        9414523:\"Redwood City\",\n",
    "                        9415141:\"Davis Point (Carquinez Br)\",\n",
    "                        # 9415020:\"Point Reyes\"\n",
    "                       }\n",
    "\n",
    "    def __init__(self,original_met_fn, run_dir, new_met_fn):\n",
    "        self.noaa_air_stations = list(self.noaa_air_stations) # don't modify originals\n",
    "        self.noaa_station_names = dict(self.noaa_station_names)\n",
    "        \n",
    "        self.original_met_fn = original_met_fn\n",
    "        self.run_dir = run_dir\n",
    "        self.new_met_fn = new_met_fn\n",
    "        self.met = dio.read_meteo_on_curvilinear(self.original_met_fn,self.run_dir,flip_grid_rows=True)\n",
    "\n",
    "        self.load_noaa_data()\n",
    "\n",
    "        temp_new = self.interpolate_new_temperature()\n",
    "\n",
    "        # Update data and write back out\n",
    "        self.met_new = self.met.copy()\n",
    "        self.met_new['air_temperature'] = self.met_new.air_temperature.dims, temp_new\n",
    "        dio.rewrite_meteo_on_curvilinear(original_met_fn,new_met_fn,self.met_new)\n",
    "        \n",
    "    def load_noaa_data(self):\n",
    "        noaa_air_temps = [ noaa_coops.coops_dataset(station,self.met.time.values[0], self.met.time.values[-1],\n",
    "                                                    ['air_temperature'],cache_dir='cache')\n",
    "                           for station in self.noaa_air_stations]\n",
    "\n",
    "        # Duplicate SF to a point to the south to keep Redwood City from bleeding out into the\n",
    "        # ocean.\n",
    "        def duplicate(original, new_ll):\n",
    "            dupe = [ds for ds in noaa_air_temps if int(ds.station.values[0])==original][0]\n",
    "            dupe = dupe.copy()\n",
    "            dupe['lon'] = dupe.lon.dims, [new_ll[0]]\n",
    "            dupe['lat'] = dupe.lat.dims, [new_ll[1]]\n",
    "            dupe['station'] = dupe.station.dims, [-original]\n",
    "            noaa_air_temps.append(dupe)\n",
    "            self.noaa_air_stations.append( -original )\n",
    "            self.noaa_station_names[-original] = self.noaa_station_names[original]+\" dupe\"\n",
    "        duplicate(9414290, [-122.5,37.5068] ) # half-moon-bay ish\n",
    "        duplicate(9414290, [-122.9,37.93] ) # point reyes-ish\n",
    "        \n",
    "        self.noaa_air_temp = xr.concat(noaa_air_temps,dim='station')\n",
    "        self.noaa_air_temp['air_temperature'] = (self.noaa_air_temp.air_temperature.dims, \n",
    "                                                 utils.fill_invalid(self.noaa_air_temp.air_temperature.values,axis=1))\n",
    "    def plot_original(self,tidx=0):\n",
    "        fig,ax=plt.subplots()\n",
    "        snap=self.met.isel(time=tidx)    \n",
    "        coll=plot_utils.pad_pcolormesh( met.x, met.y, snap['air_temperature'], ax=ax,\n",
    "                                       cmap=scmap.load_gradient('hot_desaturated.cpt'),\n",
    "                                        clim=[13,20.5])\n",
    "        #grid.plot_edges(color='k',lw=0.5,alpha=0.3,zorder=2)\n",
    "        return fig,ax\n",
    "\n",
    "    def plot_something(self):\n",
    "        fig,ax=plt.subplots(figsize=(9.5,6))\n",
    "        \n",
    "        for stn_idx,stn in enumerate(self.noaa_air_temp.station):\n",
    "            noaa_station=self.noaa_air_temp.isel(station=stn_idx)\n",
    "            name=self.noaa_station_names[int(stn.item())]\n",
    "            ls=ax.plot(noaa_station.time, noaa_station['air_temperature'], label=name,lw=2.0)\n",
    "            ll = np.r_[noaa_station.lon.values, noaa_station.lat.values]\n",
    "            xy =proj_utils.mapper('WGS84','EPSG:26910')(ll)\n",
    "            row,col = utils.nearest_2d(met.x, met.y, xy[0], xy[1])\n",
    "            ax.plot( self.met.time, self.met.air_temperature.isel(row=row,col=col),\n",
    "                     label=f\"{name} old\", color=ls[0].get_color(), lw=0.80)\n",
    "        fig.tight_layout()\n",
    "        ax.legend(loc='upper left')\n",
    "        ax.axis((19212.31300939389, 19213.87069539253, 11., 35))\n",
    "        return fig,ax\n",
    "\n",
    "    def interpolate_new_temperature(self):\n",
    "        # interpolate to grid roughly\n",
    "        noaa_ll = np.c_[self.noaa_air_temp.lon.values, self.noaa_air_temp.lat.values]\n",
    "        noaa_xy = proj_utils.mapper('WGS84','EPSG:26910')(noaa_ll)\n",
    "        met_XY = np.stack((self.met.x, self.met.y), axis=-1)\n",
    "        \n",
    "        # sort of slow to re-do the interpolation at each step, so get the set of \"footprints\"\n",
    "        # once.\n",
    "        basis_functions = [ field.XYZField(noaa_xy, np.arange(noaa_xy.shape[0])==stn_idx,default_interpolation='nearest')(met_XY)\n",
    "                            for stn_idx in range(noaa_xy.shape[0]) ]\n",
    "        \n",
    "        temp_new = self.met['air_temperature'].values.copy() # (time,row,col)\n",
    "        temp_new[:,:,:] = 0.0\n",
    "        \n",
    "        for stn_idx, basis in enumerate(basis_functions):\n",
    "            T_on_met_time = utils.interp_near(self.met.time.values, \n",
    "                                              self.noaa_air_temp.time.values, \n",
    "                                              self.noaa_air_temp.air_temperature.isel(station=stn_idx))\n",
    "            temp_new[:,:,:] += T_on_met_time[:,None,None] * basis[None,:,:]\n",
    "        return temp_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1db7d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get a basic restart going\n",
    "from stompy.model.delft import custom_process\n",
    "\n",
    "class Model(custom_process.CustomProcesses,bloom_common.SFBRestartable):\n",
    "    dwaq=True\n",
    "    temperature=True\n",
    "    \n",
    "    kd_path=\"../Kd_2022/Kd_sentinel3_1h/Kd_sent3_20220801_20220901.nc\"\n",
    "\n",
    "    inputs_static=(\"/boisevol1/hpcshared/open_bay/hydro/full_res\"\n",
    "                   \"/wy2022_r52184/sfb_dfm/inputs-static/\")\n",
    "\n",
    "    tracer_configs=[ dict(fall_velocity_m_s= -5.0/86400, release='uniform'),\n",
    "                     dict(fall_velocity_m_s=-10.0/86400, release='uniform'),\n",
    "                     #dict(fall_velocity_m_s=0, release='uniform')\n",
    "                   ]\n",
    "                    \n",
    "    seg_function_resolution=500.0 # [m] resolution when discretizing spatiotemporal parameter to cartesian grid.\n",
    "\n",
    "    overwrite_tracers=False # true to copy/update restart file to re-initialize tracers\n",
    "    overwrite_temperature=False # true to update temperature field from AVHRR \n",
    "\n",
    "    replace_ocean_temp_bc = True # Use SF Buoy water temp\n",
    "    replace_met_bc = True\n",
    "    \n",
    "    def configure_general(self):\n",
    "        bloom_common.configure_dfm_t141798()\n",
    "                \n",
    "        self.mdu['output','WaqInterval']=\"\" # no need for DWAQ output\n",
    "        self.dfm_bin_dir=os.path.join(os.environ['DELFT_SRC'],'bin')\n",
    "        self.mpi_bin_dir=os.path.join(os.environ['DELFT_SRC'],'bin')\n",
    "\n",
    "        # 2024-05-23: Getting \"flownode mismatches\", and this was 1. So trying 0...\n",
    "        self.mdu['geometry','RenumberFlowNodes']=0\n",
    "        \n",
    "        # Some files have moved around, so update locations\n",
    "        self.mdu['output','CrsFile' ] = os.path.join(self.inputs_static, \"SB-observationcrosssection.pli\")\n",
    "        self.mdu['output','MapInterval' ] = 3600\n",
    "        self.mdu['geometry','LandBoundaryFile'] = os.path.join(self.inputs_static,\"deltabay.ldb\")\n",
    "        self.mdu['geometry','FixedWeirFile'] = os.path.join(self.inputs_static,\"SBlevees_tdk.pli\")\n",
    "        self.mdu['geometry','AngLon'] = -121.0 # affects Qsun in heat budget\n",
    "\n",
    "        # run_dfm_rs_chl for other entries that may have to be dropped.\n",
    "        del self.mdu['waves','WaveNikuradse']\n",
    "\n",
    "        if not self.temperature:\n",
    "            self.mdu['physics','Temperature'] = 0 # and fix-up tracers below\n",
    "        else:\n",
    "            self.mdu['physics','Temperature'] = 5 # follows the dfm_spinup config\n",
    "            self.mdu['physics','Dalton'] = -1 # use Cd for wind stress for convective heat flux\n",
    "            self.mdu['physics','Stanton'] = -1 # use Cd for wind stress for evaporative heat flux\n",
    "\n",
    "        # for non-restart this is handled by configure(), but restart doesn't call that.\n",
    "        if self.dwaq is True:                                                                                              \n",
    "            self.dwaq=dwaq.WaqOnlineModel(model=self)\n",
    "            \n",
    "    def set_bloom_tracers(self):\n",
    "        self.my_tracers=[] # all of the new tracers, including multiple tracers for each entry of self.tracer_configs\n",
    "        \n",
    "        # I think the steps are\n",
    "        #  1. add the tracer definitions to forcing data via appending/updating FlowFMold_bnd.ext\n",
    "        #  2. add/overwrite the tracers in the restart file.\n",
    "        \n",
    "        tracers=[]\n",
    "\n",
    "        def release_2d_func(xy,cfg): # vectorized on xy\n",
    "            if 'release_poly' in cfg:\n",
    "                release_poly = cfg['release_poly']\n",
    "                in_poly = [release_poly.contains(geometry.Point(p)) for p in xy]\n",
    "                value_2d = np.array(in_poly)\n",
    "            elif cfg['release']=='rs_chl':\n",
    "                release_raster = get_initial_chl_from_RS(plot=False)\n",
    "                value_2d = release_raster(xy)\n",
    "                # raster may not be large enough to cover domain.\n",
    "                value_2d[ np.isnan(value_2d) ] = 0.0\n",
    "            elif cfg['release']=='uniform': # uniform releasee\n",
    "                value_2d = np.ones(xy.shape[0],np.float64)\n",
    "            else:\n",
    "                raise Exception(\"Expected tracer to have some release configured\")\n",
    "            return value_2d\n",
    "        \n",
    "        # Not sure whether we'll be able to do vertical swimming here,\n",
    "        # but keep the machinery around in case.\n",
    "        \n",
    "        #for swim_i,swim_speed in enumerate(self.swim_speeds): # positive down, m/s\n",
    "        for tracer_i,tracer_cfg in enumerate(self.tracer_configs):\n",
    "            # Names must be <=10 characters!\n",
    "            conc='conc' + str(tracer_i)\n",
    "            #agec='agec' + str(tracer_i)\n",
    "            #depc='depc' + str(tracer_i)\n",
    "            #radc='radc' + str(tracer_i)\n",
    "\n",
    "            # basic age. For instantaneous release we know the answer,\n",
    "            # but that will serve as a check once we attempt swimming.\n",
    "            #self.custom_CART(conc=conc,age_conc=agec)\n",
    "            #self.custom_CART(conc=conc,age_conc=depc,partial=\"LocalDepth\")\n",
    "            #self.custom_CART(conc=conc,age_conc=radc,partial='RadBot')\n",
    "\n",
    "            # Drop complicated machinery for updating vertically variable RS scenes.\n",
    "            # Even with swimming will use a mixed IC.\n",
    "            def tracer_blob(rst_ds,values_cell_layer):\n",
    "                # Dropped uniform tracer code.\n",
    "                xy=np.c_[ rst_ds.FlowElem_xzw.values, rst_ds.FlowElem_yzw.values]\n",
    "\n",
    "                value_2d = release_2d_func(xy,tracer_cfg)\n",
    "                \n",
    "                # mixed initial_condition\n",
    "                values_cell_layer[:,:] = value_2d[:,None]\n",
    "            def tracer_zero(rst_ds,values_cell_layer):\n",
    "                values_cell_layer[:,:] = 0.0\n",
    "\n",
    "            # Unsure of whether this is the right place to do settling, or if it should\n",
    "            # be through DWAQ.\n",
    "            tracers.append( dict(name=conc,func=tracer_blob,cfg=tracer_cfg))            \n",
    "            #tracers.append( dict(name=agec,func=tracer_zero,cfg=tracer_cfg))\n",
    "            #tracers.append( dict(name=depc,func=tracer_zero,cfg=tracer_cfg))\n",
    "            #tracers.append( dict(name=radc,func=tracer_zero,cfg=tracer_cfg))\n",
    "\n",
    "        for tracer in tracers:\n",
    "            # Initials don't really matter here as they are manually written to restart files.\n",
    "            self.dwaq.substances[tracer['name']]=dwaq.Substance(initial=0)\n",
    "            \n",
    "        self.my_tracers=tracers\n",
    "        # Adding the tracers to the ext file doesn't happen until copy_file_for_restart\n",
    "        # likewise, will have to modify the restart files later.\n",
    "\n",
    "    def update_restart_data(self):\n",
    "        if self.overwrite_temperature:\n",
    "            # setup global grid with temperature\n",
    "            #self.temp_on_grid = get_temperature_on_grid_avhrr(self.grid, self.run_start)\n",
    "            self.temp_on_grid = get_temperature_on_grid_acspo(self.grid, self.run_start)\n",
    "\n",
    "        def modify_ic(rst_ds,**kw):\n",
    "            if self.overwrite_tracers:\n",
    "                for tracer in self.my_tracers:\n",
    "                    name=tracer['name']\n",
    "                    func=tracer['func']\n",
    "                    self.log.info(f\"Setting tracer {name} in restart file\")\n",
    "                    # mimic sa1 tracer\n",
    "                    salt=rst_ds['sa1']\n",
    "                    values=salt.values.copy() # ('time','nFlowElem','laydim')\n",
    "                    values[...] = 0.0 # don't accidentally write salt data though\n",
    "                    \n",
    "                    # updates values in place.\n",
    "                    func(rst_ds=rst_ds,values_cell_layer=values[0,:,:])\n",
    "                    rst_ds[name]=salt.dims, values\n",
    "                    for aname in ['coordinates','grid_mapping']:\n",
    "                        if aname in salt.attrs:\n",
    "                            rst_ds[name].attrs[aname]=salt.attrs[aname]\n",
    "            if self.overwrite_temperature and self.temperature:\n",
    "                name='tem1'\n",
    "                temp=rst_ds[name]\n",
    "                values=temp.values.copy() # ('time','nFlowElem','laydim')\n",
    "\n",
    "                self.log.info(f\"Setting initial temperature field based on AVHRR or ACSPO\")\n",
    "                \n",
    "                # updates values in place.\n",
    "                xy=np.c_[ rst_ds.FlowElem_xzw.values, rst_ds.FlowElem_yzw.values]\n",
    "                cells = [self.grid.select_cells_nearest(pnt) for pnt in xy]\n",
    "                cells=np.array(cells)\n",
    "                temp_2d = self.temp_on_grid[cells]\n",
    "                values[0,:,:] = temp_2d[:,None]\n",
    "                rst_ds[name]=temp.dims, values\n",
    "                for aname in ['coordinates','grid_mapping']:\n",
    "                    if aname in temp.attrs:\n",
    "                        rst_ds[name].attrs[aname]=temp.attrs[aname]\n",
    "                \n",
    "        self.modify_restart_data(modify_ic)\n",
    "        \n",
    "    def write_ocean_temperature_bc(self,fp_new,rec):   \n",
    "        # presumably rec['FILENAME'] is in the bc_files folder, which might be shared.\n",
    "        if self.replace_ocean_temp_bc:\n",
    "            print(\"OVERWRITING OCEAN TEMPERATURE BC\")\n",
    "            temp_data = sf_buoy_data()\n",
    "            # Copy the geometry to run_dir:\n",
    "            orig_pli_fn = os.path.join(self.run_dir,rec['FILENAME'])\n",
    "            new_rel_fn = 'sea_temp_buoy.pli'\n",
    "            new_pli_fn = os.path.join(self.run_dir,new_rel_fn)\n",
    "                                \n",
    "            if orig_pli_fn!=new_pli_fn:\n",
    "                shutil.copyfile(orig_pli_fn,new_pli_fn)\n",
    "                def trim_pli(s,suffix='.pli'):\n",
    "                    assert s.endswith(suffix)\n",
    "                    return s[:-len(suffix)]\n",
    "                old_stem = trim_pli(rec['FILENAME'])\n",
    "                new_stem = trim_pli(new_rel_fn)\n",
    "                rec['FILENAME']=new_rel_fn\n",
    "                rec['stanza'] = [s.replace(old_stem,new_stem) for s in rec['stanza']]\n",
    "                \n",
    "            # Write the new data:\n",
    "            pli = dio.read_pli(new_pli_fn)\n",
    "            n_points = len(pli[0][1])\n",
    "            assert new_pli_fn.endswith('.pli')\n",
    "            for i in range(n_points):\n",
    "                node_tim_fn = new_rel_fn.replace('.pli',f'_{i:04d}.tim')\n",
    "                print(f\"Writing node data to {node_tim_fn}\")\n",
    "                # don't trim, so we can keep using this for restarts.\n",
    "                self.write_tim(temp_data,os.path.join(self.run_dir,node_tim_fn),trim_time=False)\n",
    "        else:\n",
    "            print(\"NOT Overwriting ocean temperature BC\")\n",
    "            \n",
    "        # Have to write it even if it's unchanged.\n",
    "        fp_new.write(\"\\n\".join(rec['stanza'])+\"\\n\")\n",
    "            \n",
    "    def write_met_bc(self,fp_new,rec):\n",
    "        print(\"OVERWRITING METEO BC\")\n",
    "\n",
    "        new_rel_fn = 'hac_noaa_airtemp.tem'\n",
    "        new_met_path = os.path.join(self.run_dir, new_rel_fn)\n",
    "        orig_rel_fn = rec['FILENAME']\n",
    "        orig_met_path = os.path.join(self.run_dir, orig_rel_fn)\n",
    "        MetUpdater(orig_met_path, self.run_dir, new_met_path)\n",
    "\n",
    "        if new_rel_fn != orig_rel_fn:\n",
    "            rec['FILENAME']=new_rel_fn\n",
    "            rec['stanza'] = [s.replace( orig_rel_fn, new_rel_fn) for s in rec['stanza']]\n",
    "        fp_new.write(\"\\n\".join(rec['stanza'])+\"\\n\")\n",
    "\n",
    "    def add_tracers_to_bcs(self):\n",
    "        # take a more low-level approach compared to usual BC configuration\n",
    "        # so that we can be very careful about what things change.\n",
    "        ext_fn=self.mdu.filepath(('external forcing','ExtForceFile'))\n",
    "        orig_ext_fn=ext_fn+\".orig\"\n",
    "        shutil.copyfile(ext_fn,orig_ext_fn)\n",
    "\n",
    "        print(f\"Processing forcing file, {orig_ext_fn} => {ext_fn}\")\n",
    "        bcs=self.parse_old_bc(orig_ext_fn)\n",
    "        \n",
    "        new_tracer_names=[t['name'] for t in self.my_tracers]\n",
    "        configured_tracers={}\n",
    "        \n",
    "        # For now all boundary conditions for all new tracers are 0.\n",
    "        # Note that establishing order here is very confusing. If these\n",
    "        # need to be nonzero, it will take some work to know\n",
    "        # it's correct. probably the strategy should be to filter out \n",
    "        # all existing BCs for these tracers, and then write them at the\n",
    "        # end in our prescribed order. This [I think] is what it does\n",
    "        # currently.\n",
    "        new_bc_values=[]\n",
    "        for tracer in self.my_tracers:\n",
    "            cfg=tracer['cfg']\n",
    "            if tracer['name'].startswith('conc') and cfg['release']=='uniform':\n",
    "                new_bc_values.append(1.0)\n",
    "            else:\n",
    "                new_bc_values.append(0.0)\n",
    "\n",
    "        def name_matches(cfg_name):\n",
    "            for tracer in tracers:\n",
    "                if tracer['name'].lower() == cfg_name.lower():\n",
    "                    if tracer['name']!=cfg_name:\n",
    "                        print(f\"Careful - case mismatch {cfg_name} vs {tracer['name']}\")\n",
    "                    return True\n",
    "            return False\n",
    "            \n",
    "        with open(ext_fn,'wt') as fp_new:\n",
    "            for rec in bcs:\n",
    "                #write_verbatim=True\n",
    "                \n",
    "                quantity=rec['QUANTITY']\n",
    "                \n",
    "                if quantity.upper().startswith('INITIALTRACER'):\n",
    "                    tracer_name=quantity[len(\"INITIALTRACER\"):]\n",
    "                    continue\n",
    "                elif quantity.upper().startswith('TRACERBND'):\n",
    "                    tracer_name=quantity[len(\"TRACERBND\"):]\n",
    "                    continue\n",
    "                elif ((not self.temperature) \n",
    "                      and \n",
    "                      (quantity.upper() in ['TEMPERATUREBND','INITIALTEMPERATURE',\n",
    "                                            'HUMIDITY_AIRTEMPERATURE_CLOUDINESS'])):\n",
    "                    continue\n",
    "                elif (self.temperature \n",
    "                      and (quantity.upper() == 'TEMPERATUREBND')\n",
    "                      and ('sea_temp' in rec['FILENAME'])):\n",
    "                    self.write_ocean_temperature_bc(fp_new,rec)\n",
    "                    continue\n",
    "                elif (self.temperature\n",
    "                      and (quantity.upper() == 'HUMIDITY_AIRTEMPERATURE_CLOUDINESS')\n",
    "                      and self.replace_met_bc):\n",
    "                    self.write_met_bc(fp_new,rec)\n",
    "                    continue\n",
    "                elif quantity.upper().startswith('DISCHARGE_SALINITY_TEMPERATURE_SORSIN'):\n",
    "                    print(\"Source/sink BC entry\")\n",
    "                    # Yuck - have to add or remove new column(s). This only involves rewriting \n",
    "                    # the data file,though. The stanza is unchanged.\n",
    "                    # Now that we drop temperature, I think orig_num_values goes from 3 to 2.\n",
    "                    if self.temperature:\n",
    "                        orig_num_values = 3\n",
    "                    else:\n",
    "                        #raise Exception(\"These runs should have temperature.\")\n",
    "                        orig_num_values = 2\n",
    "                    self.add_tracer_bcs(rec,new_values=new_bc_values,orig_num_values=orig_num_values)\n",
    "\n",
    "                # At this point nobody ever changes the stanza, it's all written verbatim.\n",
    "                #if write_verbatim:\n",
    "                fp_new.write(\"\\n\".join(rec['stanza'])+\"\\n\")\n",
    "                #continue\n",
    "                \n",
    "            # And write out our new tracers (including ones that were skipped during \n",
    "            # transcription above\n",
    "            for tracer,new_bc_value in zip(self.my_tracers,new_bc_values):\n",
    "                name=tracer['name']\n",
    "                ic_fn=f\"dummy-{name}.xyz\"\n",
    "                with open(os.path.join(self.run_dir,ic_fn),'wt') as fp_xyz:\n",
    "                    fp_xyz.write(f\"550000 4180000 {new_bc_value}\\n\")\n",
    "                fp_new.write(\"\\n# NEW TRACERS\\n\"\n",
    "                             f\"QUANTITY=initialtracer{name}\\n\"\n",
    "                             f\"FILENAME={ic_fn}\\n\"\n",
    "                             \"FILETYPE=7\\n\"\n",
    "                             \"METHOD=5\\n\"\n",
    "                             \"OPERAND=O\\n\")\n",
    "\n",
    "\n",
    "                w=tracer['cfg']['fall_velocity_m_s']\n",
    "                if w!=0.0:\n",
    "                    # Presumably DWAQ-based settling velocity works, too. But that would require\n",
    "                    # choosing tracers that already have a settling process associated with them,\n",
    "                    # or to code up a custom settling process. In contrast, if it works to \n",
    "                    # set constant settling here, where DFM handles it, things would be much simpler.\n",
    "                    self.log.warning(\"Hoping that fall velocity in can be set via DFM instead of DWAQ\")\n",
    "                    fp_new.write(f\"TRACERFALLVELOCITY={w:.8f}\\n\")\n",
    "            \n",
    "    def add_tracer_bcs(self,bc,new_values=[],orig_num_values=None):\n",
    "        \"\"\"\n",
    "        Add additional columns to a source/sink data file.\n",
    "        So if the new run will include two dwaq tracers, pass new_values=[0,1]\n",
    "        (which would tag sources with 0 for the first and 1.0 for the second)\n",
    "        orig_num_values: 3 for run with salinity and temperature. I think\n",
    "        less than that if temperature and/or salinity are disabled. \n",
    "        \"\"\"\n",
    "        if orig_num_values is None:\n",
    "            if self.temperature:\n",
    "                orig_num_values=3\n",
    "            else:\n",
    "                orig_num_values=2\n",
    "                \n",
    "        # yuck...\n",
    "        pli_fn=os.path.join(self.run_dir,bc['FILENAME'])\n",
    "        assert pli_fn.lower().endswith('.pli')\n",
    "        fn=pli_fn[:-4] + \".tim\"\n",
    "        assert os.path.exists(fn)\n",
    "        fn_orig=fn+\".orig\"\n",
    "        if not os.path.exists(fn_orig):\n",
    "            shutil.copyfile(fn,fn_orig)\n",
    "        data_orig=np.loadtxt(fn_orig)\n",
    "        # drop previous forcing for new tracers. leaving time column and the original Q,S,T values\n",
    "        columns=[data_orig[:,:1+orig_num_values]] \n",
    "        for new_val in new_values:\n",
    "            columns.append( np.full(data_orig.shape[0],new_val))\n",
    "        data=np.column_stack(columns)\n",
    "        np.savetxt(fn,data,fmt=\"%.6g\")\n",
    "\n",
    "    def fix_ext_paths(self):\n",
    "        # from run_dfm_rs_chl: Fix paths that have moved in external forcing file.\n",
    "        # And also in ext boundary file. \n",
    "        ext_fn=self.mdu.filepath(('external forcing','ExtForceFile'))\n",
    "        orig_ext_fn=ext_fn+\".orig\"\n",
    "        shutil.copyfile(ext_fn,orig_ext_fn)\n",
    "\n",
    "        print(f\"Trying to fix_ext_paths in {orig_ext_fn} => {ext_fn}\")\n",
    "        with open(orig_ext_fn,'rt') as fp_orig:\n",
    "            with open(ext_fn,'wt') as fp_new:\n",
    "                for line in fp_orig:\n",
    "                    m=re.match(r'\\s*filename\\s*=\\s*([^#]+)(#.*)?',line,re.I)\n",
    "                    if m:\n",
    "                        ext_entry = m.group(1).strip()\n",
    "                        # print(f\"Checking on filename {ext_entry} in external forcing file\")\n",
    "                        # or should it be the original run directory instead of self.run_dir?\n",
    "                        real_path=os.path.abspath(os.path.join(self.run_dir,ext_entry))\n",
    "                        if not os.path.exists(real_path):\n",
    "                            # If it's from inputs-static replace\n",
    "                            if os.path.dirname(real_path).endswith('inputs-static'):\n",
    "                                real_path = os.path.join(self.inputs_static, os.path.basename(real_path))\n",
    "                                assert os.path.exists(real_path)\n",
    "                                line=f\"FILENAME={real_path}\\n\"\n",
    "                            else:\n",
    "                                raise Exception(\"redirect here\")\n",
    "                    fp_new.write(line)\n",
    "\n",
    "    def add_light(self):\n",
    "        if self.kd_path is None: return\n",
    "        self.add_kd()\n",
    "        self.dwaq.add_process(name='CalcRad')\n",
    "        self.add_insolation()\n",
    "        # For online coupling this probably has to be put somewhere else.\n",
    "        self.dwaq.map_output += ('RadBot','ExtVl')\n",
    "        \n",
    "    def add_insolation(self):\n",
    "        if 0:\n",
    "            self.dwaq.parameters['RadSurf']=500.0 \n",
    "        else:\n",
    "            cimis=xr.open_dataset('/richmondvol1/hpcshared/inputs/cimis/union_city-hourly-2022_bloom.nc')\n",
    "            # Starts as PST, but the model is UTC.\n",
    "            cimis=cimis.set_coords('time').swap_dims({'Date':'time'})\n",
    "            cimis['time']=cimis['time']+np.timedelta64(8,'h')\n",
    "            sol_rad=cimis['HlySolRad'].values\n",
    "            sol_rad=utils.fill_invalid(sol_rad)\n",
    "            \n",
    "            #t0=np.datetime64(self.hydro.time0)\n",
    "            #t_secs=((cimis.time.values-t0)/np.timedelta64(1,'s')).astype(np.int64)\n",
    "            param=dwaq.ParameterTemporal(times=cimis.time.values,values=sol_rad)\n",
    "            self.dwaq.parameters['RadSurf'] = param\n",
    "        \n",
    "    def add_kd(self):\n",
    "        if 0: \n",
    "            self.log.warning('Using constant Kd field until online parameter code comes along')\n",
    "            self.dwaq.parameters['ExtVl'] = dwaq.ParameterConstant(1.0)\n",
    "            return\n",
    "\n",
    "        # extrude to 3D, write seg function (which for an online run will be converted to\n",
    "        # cartesian grid).\n",
    "        ds=xr.open_dataset(self.kd_path)\n",
    "        g=unstructured_grid.UnstructuredGrid.read_ugrid(ds)\n",
    "        if not np.allclose(g.cells_centroid(), self.grid.cells_centroid()):\n",
    "            self.log.warning(\"Kd field grid is different. Will try to match to hydro grid by centroid\")\n",
    "            n_map,e_map,c_map = self.grid.match_to_grid(g,tol=np.inf)\n",
    "            # self.match_to_grid(other) returns arrays that can be used to map other_grid_data[c_map]\n",
    "            # back to self. unlimited tolerance so c_map should have valid indexes everywhere.\n",
    "            permute = c_map                \n",
    "        else:\n",
    "            permute = np.arange(g.Ncells())\n",
    "        #t0=np.datetime64(self.hydro.time0)\n",
    "        #tsecs=(ds.time.values-t0)/np.timedelta64(1,'s')\n",
    "        def seg_func(t,permute=permute):\n",
    "            C_2d=ds['Kd'].sel(time=t,method='nearest').values\n",
    "            return self.dwaq.hydro.extrude_element_to_segment(C_2d[permute])\n",
    "            \n",
    "        # No self-shading, specify overall extinction directly\n",
    "        self.dwaq.parameters['ExtVl'] = dwaq.ParameterSpatioTemporal(times=ds.time.values,func_t=seg_func)\n",
    "\n",
    "class DFMBloomTracer: \n",
    "    # v00: just get a run to start...\n",
    "    # v01: Swimming.\n",
    "    # v02: more swimming, fewer tracers, maybe RS initial condition.\n",
    "    # v03: adding temperature with RS initialization\n",
    "    # v04: Fixing temperature bugs in script and hopefully better BC values.\n",
    "    # v05: Decrease Dalton and Stanton, switch to 5 m/d swimming. See if setting\n",
    "    #      initial tracer fixes unset tracer BCs.\n",
    "    # v06: No temperature, include 5,10 m/d. Drop radc\n",
    "    # v07: Temperature, same as v05, but keep 5,10 m/d like v06.\n",
    "    # v08: Temperature, using ACSPO instead of AVHRR, and shift initial time to line up the\n",
    "    #      instantaneous and daily-composite signals better.\n",
    "    name=\"bloom_tracers_v08\"\n",
    "    \n",
    "    # Will start from the end of this existing run (which doesn't have the tracers)\n",
    "    dfm_base_run_dir=\"dfm_spinup\"\n",
    "    \n",
    "    restart_copy_names=[\"source_files\"] # copy, because we end up modifying some\n",
    "\n",
    "    # Will be an instantaneous release -- first phase is to run from the restart (8/1)\n",
    "    # up to the time of the release.\n",
    "    # The sentinel 3 data appears to be from 18:11 to 18:38. Assuming that's UTC, which \n",
    "    # the model is, too.\n",
    "    end_time = np.datetime64(\"2022-08-30\")\n",
    "\n",
    "    def run_schedule(self):\n",
    "        # If there isn't a run that ends at self.temp_scene_time, run it.\n",
    "        \n",
    "        # IC temperature field is a daily composite. That's roughly centered\n",
    "        # 12:00 local time, which is 20:00 UTC. But really this is based on \n",
    "        # looking at the timeseries and choosing a start time that seems to\n",
    "        # get good agreement between in situ instantaneous and the daily composite\n",
    "        # from satellite. Note that this comparison was made using AVHRR data, but\n",
    "        # the run is now using ACSPO data, which is colder in Central Bay on this\n",
    "        # day, by 1-1.5 degC.\n",
    "        temp_time0=np.datetime64(\"2022-08-02 19:30\") # 24-h composite. \n",
    "        release_time = np.datetime64(\"2022-08-04 18:20\")\n",
    "\n",
    "        kw=dict(temperature=True)\n",
    "\n",
    "        restart_for_temp = self.run_from_spinup(t_stop=temp_time0,\n",
    "                                                replace_ocean_temp_bc = True, \n",
    "                                                replace_met_bc = True,\n",
    "                                                **kw)\n",
    "\n",
    "        # Set temperature field on 8/2, and tracer release on 8/4\n",
    "        #    run1=self.run_from_resume(t_start=temp_time0, t_stop=release_time, overwrite_temperature=True)\n",
    "        #    run2=self.run_from_resume(t_start=release_time, t_stop=self.end_time, overwrite_tracers=True)\n",
    "        \n",
    "        # For uniform run, no need to time the tracer release\n",
    "        run1=self.run_from_resume(t_start=temp_time0, t_stop=self.end_time, \n",
    "                                  overwrite_temperature=True, overwrite_tracers=True,\n",
    "                                  replace_ocean_temp_bc = True, # in the future this will also be in place.\n",
    "                                  replace_met_bc = False, # should already be in place\n",
    "                                  **kw)\n",
    "\n",
    "    def run_from_spinup(self,t_stop,**kw):\n",
    "        \"\"\"\n",
    "        Run from a restart point in the spinup run until t_stop\n",
    "        If such a run exists, return its path, otherwise run and return the new path \n",
    "        \"\"\"\n",
    "        match=self.matching_run(t_stop=t_stop)\n",
    "        if match is not None:\n",
    "            return match\n",
    "        \n",
    "        prev_model=Model.load(self.dfm_base_run_dir)            \n",
    "        start_time=prev_model.restartable_time()\n",
    "        assert start_time < t_stop,f\"Need to scan for restart time before last restart\"\n",
    "\n",
    "        # Setup a restart\n",
    "        model=prev_model.create_restart(deep=True,**kw) \n",
    "        model.run_stop=t_stop\n",
    "        self.setup_and_run(model)\n",
    "        return model.run_dir\n",
    "\n",
    "    def run_from_resume(self, t_start, t_stop,**kw):\n",
    "        \"\"\"\n",
    "        Check for the most recent completed run ending at the release time.\n",
    "        None if not found.\n",
    "        Configure restart\n",
    "        \"\"\"\n",
    "        this_run = self.matching_run(t_start=t_start,t_stop=t_stop)\n",
    "        if this_run is not None:\n",
    "            print(\"Resume: {t_start} -- {t_stop} => Already exists {this_run}\")\n",
    "            return this_run\n",
    "\n",
    "        prev_run = self.matching_run(t_stop = t_start)\n",
    "        if prev_run is None:\n",
    "            print(\"No completed runs end at time of release\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"Will use {prev_run} as previous run\")\n",
    "        prev_model = Model.load(prev_run)\n",
    "            \n",
    "        # Setup a restart\n",
    "        model=prev_model.create_restart(deep=True,**kw)\n",
    "        model.run_stop=self.end_time\n",
    "        self.setup_and_run(model)\n",
    "        return model.run_dir\n",
    "\n",
    "    def setup_and_run(self,model):\n",
    "        self.set_run_dir(model)\n",
    "        model.configure_general()\n",
    "        \n",
    "        # populates self.my_tracers as a list of dictionaries\n",
    "        # with ICs, names, etc.\n",
    "        model.set_bloom_tracers()\n",
    "        model.add_light()\n",
    "            \n",
    "        # This alters the MDU, so do it before write()\n",
    "        model.update_restart_data()\n",
    "        model.write()\n",
    "        \n",
    "        # Can fix some things in ext forcing file now\n",
    "        model.fix_ext_paths()\n",
    "        # This updates the BC data in place. Do it here so that \n",
    "        # we have a starting ext file which will be updated with\n",
    "        # new tracers.\n",
    "        model.add_tracers_to_bcs()\n",
    "        model.partition()\n",
    "        model.run_simulation()\n",
    "            \n",
    "    run_dir_prefix=\"run\"\n",
    "    def set_run_dir(self,model):\n",
    "        start_str,stop_str=[ utils.to_datetime(t).strftime(\"%Y%m%dT%H%M\")\n",
    "                            for t in [model.run_start,model.run_stop]]\n",
    "        for x in range(20):\n",
    "            run_dir=os.path.join(self.name,f\"{self.run_dir_prefix}_{start_str}_{stop_str}_v{x:02}\")\n",
    "            if not os.path.exists(run_dir): break\n",
    "        else:\n",
    "            raise Exception(f\"Too many retries for {run_dir}\")\n",
    "        model.run_dir=run_dir\n",
    "        model.set_restart_file() # kludge. RestartFile needs run_dir.\n",
    "    def pattern_for_run(self,t_stop):\n",
    "        \"\"\" Glob pattern for runs ending at t_stop, aside from the initial\"\"\"\n",
    "        stop_str = utils.strftime(t_stop,\"%Y%m%dT%H%M\")\n",
    "        return os.path.join(self.name,f\"{self.run_dir_prefix}_*_{stop_str}_v*\")\n",
    "\n",
    "    def matching_run(self,t_stop=None, t_start=None):\n",
    "        candidates = glob.glob(self.pattern_for_run(t_stop))\n",
    "        candidates.sort(reverse=True) # consider later versions first.\n",
    "        for candidate in candidates: \n",
    "            if Model.run_completed(candidate):\n",
    "                return candidate\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "039c6e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HydroModel:set_restart_file: Setting RestartFile based on self.restart_from\n",
      "INFO:HydroModel:set_restart_file: Setting RestartFile based on self.restart_from\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use bloom_tracers_v08/run_20220801T0000_20220802T1930_v03 as previous run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:HydroModel:Kd field grid is different. Will try to match to hydro grid by centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking finite geometry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Setting tracer conc0 in restart file\n",
      "INFO:HydroModel:Setting tracer conc1 in restart file\n",
      "INFO:HydroModel:Setting initial temperature field based on AVHRR or ACSPO\n",
      "INFO:HydroModel:Updating RestartFile to wy2022_bloom_16layer_20220802_193000_rst.nc\n",
      "INFO:HydroModel:Could not find BC to get initial water level\n",
      "INFO:WaqOnlineModel:Updating mdu with Delwaq settings...\n",
      "INFO:WaqOnlineModel:Writing Delwaq model files...\n",
      "WARNING:nefis:Scenario does not supply proc_path. Process DB unavailable (mostly just affects names)\n",
      "INFO:WaqOnlineModel:Ignoring only_active for online WAQ configuration\n",
      "WARNING:HydroModel:SKIPPING self.set_restart_file()\n",
      "INFO:DFlowModel:Writing MDU to bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/wy2022_bloom_16layer.mdu\n",
      "INFO:HydroModel:Symlink bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/bc_files => ../run_20220801T0000_20220802T1930_v03/bc_files\n",
      "INFO:HydroModel:Copy bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/source_files => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/source_files\n",
      "INFO:HydroModel:Symlink bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/meteo_coarse.grd => ../run_20220801T0000_20220802T1930_v03/meteo_coarse.grd\n",
      "INFO:WaqOnlineModel:Wrote ExtVl to bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/seg-ExtVl.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would be writing temporal parameter to external forcing file\n",
      "Trying to fix_ext_paths in bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/FlowFMold_bnd.ext.orig => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/FlowFMold_bnd.ext\n",
      "Processing forcing file, bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/FlowFMold_bnd.ext.orig => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/FlowFMold_bnd.ext\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "Source/sink BC entry\n",
      "OVERWRITING OCEAN TEMPERATURE BC\n",
      "Writing node data to sea_temp_buoy_0000.tim\n",
      "Writing node data to sea_temp_buoy_0001.tim\n",
      "Writing node data to sea_temp_buoy_0002.tim\n",
      "Writing node data to sea_temp_buoy_0003.tim\n",
      "Writing node data to sea_temp_buoy_0004.tim\n",
      "Writing node data to sea_temp_buoy_0005.tim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:HydroModel:Hoping that fall velocity in can be set via DFM instead of DWAQ\n",
      "WARNING:HydroModel:Hoping that fall velocity in can be set via DFM instead of DWAQ\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0000_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0000_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0001_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0001_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0002_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0002_net.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top of partition: num_procs=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0003_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0003_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0004_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0004_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0005_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0005_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0006_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0006_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0007_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0007_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0008_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0008_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0009_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0009_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0010_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0010_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0011_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0011_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0012_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0012_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0013_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0013_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0014_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0014_net.nc\n",
      "INFO:HydroModel:Copying pre-partitioned grid files: bloom_tracers_v08/run_20220801T0000_20220802T1930_v03/sfei_v20_0015_net.nc => bloom_tracers_v08/run_20220802T1930_20220830T0000_v00/sfei_v20_0015_net.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to call ['/opt/anaconda3/envs/dfm_t141798/bin/generate_parallel_mdu.sh', 'wy2022_bloom_16layer.mdu', '16', '6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HydroModel:Running command: /opt/anaconda3/envs/dfm_t141798/bin/mpiexec -n 16 /opt/anaconda3/envs/dfm_t141798/bin/dflowfm -t 1 --autostartstop wy2022_bloom_16layer.mdu --processlibrary /opt/anaconda3/envs/dfm_t141798/share/delft3d/proc_def.def\n"
     ]
    }
   ],
   "source": [
    "bloto=DFMBloomTracer()\n",
    "\n",
    "bloto.run_schedule()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
